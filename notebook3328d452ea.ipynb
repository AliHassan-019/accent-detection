{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 9812,
          "sourceType": "datasetVersion",
          "datasetId": 5793
        },
        {
          "sourceId": 7063848,
          "sourceType": "datasetVersion",
          "datasetId": 4067020
        }
      ],
      "dockerImageVersionId": 30527,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "notebook3328d452ea",
      "provenance": [],
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "43fff3addb1c4f97bedfef3331b914b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5bfd75b4007c4eae9ba11139748a41d0",
              "IPY_MODEL_fa0a05507d024132995d08144f0c630d",
              "IPY_MODEL_9a6f53133f6a49ab968e19e42f731e1a"
            ],
            "layout": "IPY_MODEL_28d93d220efc47e7ac3403976fb28079",
            "tabbable": null,
            "tooltip": null
          }
        },
        "5bfd75b4007c4eae9ba11139748a41d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_092c4afc0c024ff9bff657469d34c9e4",
            "placeholder": "​",
            "style": "IPY_MODEL_797f47e7d3c242228a043311bf4c8854",
            "tabbable": null,
            "tooltip": null,
            "value": "tokenizer_config.json: 100%"
          }
        },
        "fa0a05507d024132995d08144f0c630d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_d0ed071742f64254a802206e37badf01",
            "max": 163,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c946eeb8ed0c4ea380e95ce8cefd3f26",
            "tabbable": null,
            "tooltip": null,
            "value": 163
          }
        },
        "9a6f53133f6a49ab968e19e42f731e1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_7c58587daab2479b9c5752512c01688a",
            "placeholder": "​",
            "style": "IPY_MODEL_c51a8075383d405f8ad00812fc80c5ed",
            "tabbable": null,
            "tooltip": null,
            "value": " 163/163 [00:00&lt;00:00, 11.5kB/s]"
          }
        },
        "28d93d220efc47e7ac3403976fb28079": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "092c4afc0c024ff9bff657469d34c9e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "797f47e7d3c242228a043311bf4c8854": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "d0ed071742f64254a802206e37badf01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c946eeb8ed0c4ea380e95ce8cefd3f26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7c58587daab2479b9c5752512c01688a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c51a8075383d405f8ad00812fc80c5ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "f7f5ddce48f748159a4c337230cb05af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1b2853d9c33c4d9baab1f45acecb3fbf",
              "IPY_MODEL_ab2549ff2b92436c8d0d85c752db9af4",
              "IPY_MODEL_3ada43269cc84c6ba4d3c76b97a7286a"
            ],
            "layout": "IPY_MODEL_f045e1ad135144d799caf6aae6d16b13",
            "tabbable": null,
            "tooltip": null
          }
        },
        "1b2853d9c33c4d9baab1f45acecb3fbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_8b939defa0844ad4ba3bb5161dd944ec",
            "placeholder": "​",
            "style": "IPY_MODEL_39d147ff0632421fbaae38fa1e65dd50",
            "tabbable": null,
            "tooltip": null,
            "value": "vocab.json: 100%"
          }
        },
        "ab2549ff2b92436c8d0d85c752db9af4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_fa6bfad4cb2346589aaf1d600f1d5da5",
            "max": 291,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f1c8390f4b8c4e9482ad4d7d9b019b1a",
            "tabbable": null,
            "tooltip": null,
            "value": 291
          }
        },
        "3ada43269cc84c6ba4d3c76b97a7286a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_7964549138f7470a9d3d1112df941731",
            "placeholder": "​",
            "style": "IPY_MODEL_3fa44b3037624f7db640932d621496a0",
            "tabbable": null,
            "tooltip": null,
            "value": " 291/291 [00:00&lt;00:00, 16.7kB/s]"
          }
        },
        "f045e1ad135144d799caf6aae6d16b13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b939defa0844ad4ba3bb5161dd944ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39d147ff0632421fbaae38fa1e65dd50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "fa6bfad4cb2346589aaf1d600f1d5da5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1c8390f4b8c4e9482ad4d7d9b019b1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7964549138f7470a9d3d1112df941731": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fa44b3037624f7db640932d621496a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "4428b9bd5f954d1388615638438c946c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fa103171dd2b4ed4a5b23b5f79f42b17",
              "IPY_MODEL_0ed9dd8aec9f4a098ede3869b74172d6",
              "IPY_MODEL_bda73b23cf40490fb44b4582482fd4d0"
            ],
            "layout": "IPY_MODEL_c9e4b898ec7d4f069e72324dcaa63135",
            "tabbable": null,
            "tooltip": null
          }
        },
        "fa103171dd2b4ed4a5b23b5f79f42b17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_1a77ee2311c14b7ab4fb017d0652f1e0",
            "placeholder": "​",
            "style": "IPY_MODEL_bc0307c247454b238d07420c383f6350",
            "tabbable": null,
            "tooltip": null,
            "value": "special_tokens_map.json: 100%"
          }
        },
        "0ed9dd8aec9f4a098ede3869b74172d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_e747f27158654236ba3f6f27d5c88f71",
            "max": 85,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d59ce1e0e67c4e57934e0ce65f00cdd2",
            "tabbable": null,
            "tooltip": null,
            "value": 85
          }
        },
        "bda73b23cf40490fb44b4582482fd4d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_140b3e16d7bf4fd9bbdaa7bfd49612cd",
            "placeholder": "​",
            "style": "IPY_MODEL_e0e1356f45e0493b899c16e53db7e021",
            "tabbable": null,
            "tooltip": null,
            "value": " 85.0/85.0 [00:00&lt;00:00, 9.46kB/s]"
          }
        },
        "c9e4b898ec7d4f069e72324dcaa63135": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a77ee2311c14b7ab4fb017d0652f1e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc0307c247454b238d07420c383f6350": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "e747f27158654236ba3f6f27d5c88f71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d59ce1e0e67c4e57934e0ce65f00cdd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "140b3e16d7bf4fd9bbdaa7bfd49612cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0e1356f45e0493b899c16e53db7e021": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AliHassan-019/accent-detection/blob/main/notebook3328d452ea.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "!pip install kagglehub\n",
        "\n",
        "import kagglehub\n",
        "mozillaorg_common_voice_path = kagglehub.dataset_download('mozillaorg/common-voice')\n",
        "edolele_speech_commends_path = kagglehub.dataset_download('edolele/speech-commends')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WhFaxjvOWMv",
        "outputId": "c229cdb6-5788-4fd6-f2ad-7d55db85f5d2"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kagglehub in c:\\users\\master\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.3.13)\n",
            "Requirement already satisfied: packaging in c:\\users\\master\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from kagglehub) (25.0)\n",
            "Requirement already satisfied: pyyaml in c:\\users\\master\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from kagglehub) (6.0.2)\n",
            "Requirement already satisfied: requests in c:\\users\\master\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from kagglehub) (2.32.5)\n",
            "Requirement already satisfied: tqdm in c:\\users\\master\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\master\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->kagglehub) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\master\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->kagglehub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\master\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->kagglehub) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\master\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->kagglehub) (2025.8.3)\n",
            "Requirement already satisfied: colorama in c:\\users\\master\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm->kagglehub) (0.4.6)\n",
            "Download already complete (12931472693 bytes).\n",
            "Extracting files...\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/edolele/speech-commends?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2.25G/2.25G [07:42<00:00, 5.23MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": 6
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing libraries, loading and transforming data"
      ],
      "metadata": {
        "id": "D_U2rnc3OWMw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q evaluate transformers==4.28.1\n",
        "!pip install -U -q datasets\n",
        "!pip install -q torchaudio==0.12.0+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html\n",
        "!add-apt-repository -y ppa:savoury1/ffmpeg4\n",
        "!apt-get -qq install -y ffmpeg\n",
        "!pip install -q mlflow"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:03:01.989386Z",
          "iopub.execute_input": "2023-11-28T02:03:01.990126Z",
          "iopub.status.idle": "2023-11-28T02:05:54.021447Z",
          "shell.execute_reply.started": "2023-11-28T02:03:01.990093Z",
          "shell.execute_reply": "2023-11-28T02:05:54.020111Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ox6rkKK7OWMx",
        "outputId": "14572b0f-992a-4891-90d0-c62fa65bed83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  WARNING: The scripts hf.exe, huggingface-cli.exe and tiny-agents.exe are installed in 'C:\\Users\\MASTER\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\Scripts' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
            "  WARNING: The script transformers-cli.exe is installed in 'C:\\Users\\MASTER\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\Scripts' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
            "  WARNING: The script datasets-cli.exe is installed in 'C:\\Users\\MASTER\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\Scripts' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
            "  WARNING: The script evaluate-cli.exe is installed in 'C:\\Users\\MASTER\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\Scripts' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
            "ERROR: Ignored the following yanked versions: 2.0.0\n",
            "ERROR: Could not find a version that satisfies the requirement torchaudio==0.12.0+cu113 (from versions: 2.0.1, 2.0.2, 2.1.0, 2.1.1, 2.1.2, 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.5.0, 2.5.1, 2.6.0, 2.7.0, 2.7.1, 2.8.0)\n",
            "ERROR: No matching distribution found for torchaudio==0.12.0+cu113\n",
            "'add-apt-repository' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "'apt-get' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "  WARNING: The script waitress-serve.exe is installed in 'C:\\Users\\MASTER\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\Scripts' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
            "  WARNING: The script sqlformat.exe is installed in 'C:\\Users\\MASTER\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\Scripts' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
            "  WARNING: The script mako-render.exe is installed in 'C:\\Users\\MASTER\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\Scripts' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
            "  WARNING: The script uvicorn.exe is installed in 'C:\\Users\\MASTER\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\Scripts' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
            "  WARNING: The scripts pyrsa-decrypt.exe, pyrsa-encrypt.exe, pyrsa-keygen.exe, pyrsa-priv2pub.exe, pyrsa-sign.exe and pyrsa-verify.exe are installed in 'C:\\Users\\MASTER\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\Scripts' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
            "  WARNING: The script flask.exe is installed in 'C:\\Users\\MASTER\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\Scripts' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
            "  WARNING: The script fastapi.exe is installed in 'C:\\Users\\MASTER\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\Scripts' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
            "  WARNING: The script alembic.exe is installed in 'C:\\Users\\MASTER\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\Scripts' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
            "  WARNING: The script mlflow.exe is installed in 'C:\\Users\\MASTER\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\Scripts' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
            "  WARNING: The script mlflow.exe is installed in 'C:\\Users\\MASTER\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\Scripts' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
          ]
        }
      ],
      "execution_count": 7
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Torch audio tutorial"
      ],
      "metadata": {
        "id": "A4CqvDtGOWMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchaudio\n",
        "import sys\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython.display as ipd\n",
        "\n",
        "from tqdm import tqdm\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:05:54.024129Z",
          "iopub.execute_input": "2023-11-28T02:05:54.025014Z",
          "iopub.status.idle": "2023-11-28T02:05:55.352452Z",
          "shell.execute_reply.started": "2023-11-28T02:05:54.024967Z",
          "shell.execute_reply": "2023-11-28T02:05:55.350879Z"
        },
        "trusted": true,
        "id": "YgRwQwKHOWMy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from torchaudio.datasets import SPEECHCOMMANDS\n",
        "import os\n",
        "\n",
        "\n",
        "class SubsetSC(SPEECHCOMMANDS):\n",
        "    def __init__(self, subset: str = None):\n",
        "        super().__init__(root = \"/kaggle/input/\", url = '.', download=False, folder_in_archive='speech-commends/')\n",
        "\n",
        "        def load_list(filename):\n",
        "            filepath = os.path.join(self._path, filename)\n",
        "            with open(filepath) as fileobj:\n",
        "\n",
        "                return [os.path.normpath(os.path.join(self._path, line.strip())) for line in fileobj]\n",
        "\n",
        "        if subset == \"validation\":\n",
        "            self._walker = load_list(\"validation_list.txt\")\n",
        "        elif subset == \"testing\":\n",
        "            self._walker = load_list(\"testing_list.txt\")\n",
        "        elif subset == \"training\":\n",
        "            excludes = load_list(\"validation_list.txt\") + load_list(\"testing_list.txt\")\n",
        "            excludes = set(excludes)\n",
        "            self._walker = [w for w in self._walker if w not in excludes]\n",
        "\n",
        "\n",
        "# Create training and testing split of the data. We do not use validation in this tutorial.\n",
        "train_set = SubsetSC(\"training\")\n",
        "test_set = SubsetSC(\"testing\")\n",
        "\n",
        "waveform, sample_rate, label, speaker_id, utterance_number = train_set[0]\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:05:55.355009Z",
          "iopub.execute_input": "2023-11-28T02:05:55.357044Z",
          "iopub.status.idle": "2023-11-28T02:06:05.305646Z",
          "shell.execute_reply.started": "2023-11-28T02:05:55.35698Z",
          "shell.execute_reply": "2023-11-28T02:06:05.304626Z"
        },
        "trusted": true,
        "id": "4XSzYNigOWMy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_set._path"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:06:05.307832Z",
          "iopub.execute_input": "2023-11-28T02:06:05.308176Z",
          "iopub.status.idle": "2023-11-28T02:06:05.315054Z",
          "shell.execute_reply.started": "2023-11-28T02:06:05.308147Z",
          "shell.execute_reply": "2023-11-28T02:06:05.314131Z"
        },
        "trusted": true,
        "id": "lb59joPMOWMy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of waveform: {}\".format(waveform.size()))\n",
        "print(\"Sample rate of waveform: {}\".format(sample_rate))\n",
        "\n",
        "plt.plot(waveform.t().numpy());"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:06:19.675614Z",
          "iopub.execute_input": "2023-11-28T02:06:19.676266Z",
          "iopub.status.idle": "2023-11-28T02:06:19.978712Z",
          "shell.execute_reply.started": "2023-11-28T02:06:19.676232Z",
          "shell.execute_reply": "2023-11-28T02:06:19.973627Z"
        },
        "trusted": true,
        "id": "2WJKXhkKOWMz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ['no',\n",
        " 'two',\n",
        " 'backward',\n",
        " 'four',\n",
        " 'five',\n",
        " 'nine',\n",
        " 'right',\n",
        " 'follow',\n",
        " 'visual',\n",
        " 'off',\n",
        " 'yes',\n",
        " 'six',\n",
        " 'dog',\n",
        " 'learn',\n",
        " 'left',\n",
        " 'bird',\n",
        " 'forward',\n",
        " 'wow',\n",
        " 'zero',\n",
        " 'eight',\n",
        " 'bed',\n",
        " 'go',\n",
        " 'house',\n",
        " 'tree',\n",
        " 'seven',\n",
        " 'on',\n",
        " 'three',\n",
        " 'one',\n",
        " 'down',\n",
        " 'stop',\n",
        " 'up',\n",
        " 'happy',\n",
        " 'marvin',\n",
        " 'cat',\n",
        " 'sheila']"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:06:19.981041Z",
          "iopub.execute_input": "2023-11-28T02:06:19.981619Z",
          "iopub.status.idle": "2023-11-28T02:06:19.989337Z",
          "shell.execute_reply.started": "2023-11-28T02:06:19.98158Z",
          "shell.execute_reply": "2023-11-28T02:06:19.988014Z"
        },
        "trusted": true,
        "id": "zK5FDJ_VOWMz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "waveform_first, *_ = train_set[0]\n",
        "ipd.Audio(waveform_first.numpy(), rate=sample_rate)\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:06:19.990919Z",
          "iopub.execute_input": "2023-11-28T02:06:19.99126Z",
          "iopub.status.idle": "2023-11-28T02:06:20.01696Z",
          "shell.execute_reply.started": "2023-11-28T02:06:19.991226Z",
          "shell.execute_reply": "2023-11-28T02:06:20.015993Z"
        },
        "trusted": true,
        "id": "BIjsQNZeOWMz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "waveform_second, *_ = train_set[-1]\n",
        "ipd.Audio(waveform_second.numpy(), rate=sample_rate)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:06:20.01921Z",
          "iopub.execute_input": "2023-11-28T02:06:20.019504Z",
          "iopub.status.idle": "2023-11-28T02:06:20.034082Z",
          "shell.execute_reply.started": "2023-11-28T02:06:20.019478Z",
          "shell.execute_reply": "2023-11-28T02:06:20.032871Z"
        },
        "trusted": true,
        "id": "qdyF-tEEOWMz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "new_sample_rate = 8000\n",
        "transform = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=new_sample_rate)\n",
        "transformed = transform(waveform_second)\n",
        "\n",
        "ipd.Audio(transformed.numpy(), rate=new_sample_rate)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:06:20.035797Z",
          "iopub.execute_input": "2023-11-28T02:06:20.03615Z",
          "iopub.status.idle": "2023-11-28T02:06:20.047529Z",
          "shell.execute_reply.started": "2023-11-28T02:06:20.036119Z",
          "shell.execute_reply": "2023-11-28T02:06:20.046601Z"
        },
        "trusted": true,
        "id": "2-8ajFKvOWMz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def label_to_index(word):\n",
        "    # Return the position of the word in labels\n",
        "    return torch.tensor(labels.index(word))\n",
        "\n",
        "\n",
        "def index_to_label(index):\n",
        "    # Return the word corresponding to the index in labels\n",
        "    # This is the inverse of label_to_index\n",
        "    return labels[index]\n",
        "\n",
        "\n",
        "word_start = \"yes\"\n",
        "index = label_to_index(word_start)\n",
        "word_recovered = index_to_label(index)\n",
        "\n",
        "print(word_start, \"-->\", index, \"-->\", word_recovered)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:06:20.048771Z",
          "iopub.execute_input": "2023-11-28T02:06:20.049143Z",
          "iopub.status.idle": "2023-11-28T02:06:20.056488Z",
          "shell.execute_reply.started": "2023-11-28T02:06:20.049107Z",
          "shell.execute_reply": "2023-11-28T02:06:20.055603Z"
        },
        "trusted": true,
        "id": "4WcAixD8OWM0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "为了将由录音和话语组成的数据点列表转换为模型的两个批处理张量，我们实现了PyTorch DataLoader使用的collate函数，该函数允许我们分批遍历数据集。有关使用校对函数的更多信息，请参阅文档。\n",
        "\n",
        "\n",
        "\n",
        "在整理函数中，我们还应用了重采样和文本编码。\n",
        "\n"
      ],
      "metadata": {
        "id": "H9bRBffVOWM0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_sequence(batch):\n",
        "    # Make all tensor in a batch the same length by padding with zeros\n",
        "    batch = [item.t() for item in batch]\n",
        "    batch = torch.nn.utils.rnn.pad_sequence(batch, batch_first=True, padding_value=0.)\n",
        "    return batch.permute(0, 2, 1)\n",
        "\n",
        "\n",
        "def collate_fn(batch):\n",
        "\n",
        "    # A data tuple has the form:\n",
        "    # waveform, sample_rate, label, speaker_id, utterance_number\n",
        "\n",
        "    tensors, targets = [], []\n",
        "\n",
        "    # Gather in lists, and encode labels as indices\n",
        "    for waveform, _, label, *_ in batch:\n",
        "        tensors += [waveform]\n",
        "        targets += [label_to_index(label)]\n",
        "\n",
        "    # Group the list of tensors into a batched tensor\n",
        "    tensors = pad_sequence(tensors)\n",
        "    targets = torch.stack(targets)\n",
        "\n",
        "    return tensors, targets\n",
        "\n",
        "\n",
        "batch_size = 256\n",
        "\n",
        "device = 'cuda'\n",
        "\n",
        "if device == \"cuda\":\n",
        "    num_workers = 1\n",
        "    pin_memory = True\n",
        "else:\n",
        "    num_workers = 0\n",
        "    pin_memory = False\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_set,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_fn,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=pin_memory,\n",
        ")\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_set,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    drop_last=False,\n",
        "    collate_fn=collate_fn,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=pin_memory,\n",
        ")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:06:20.057629Z",
          "iopub.execute_input": "2023-11-28T02:06:20.058283Z",
          "iopub.status.idle": "2023-11-28T02:06:20.067709Z",
          "shell.execute_reply.started": "2023-11-28T02:06:20.058247Z",
          "shell.execute_reply": "2023-11-28T02:06:20.066696Z"
        },
        "trusted": true,
        "id": "tFjHZeb9OWM0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "为了将由录音和话语组成的数据点列表转换为模型的两个批处理张量，我们实现了PyTorch DataLoader使用的collate函数，该函数允许我们分批遍历数据集。在本教程中，我们将使用卷积神经网络来处理原始音频数据。通常对音频数据进行更高级的变换，但cnn可以用来准确地处理原始数据。具体的体系结构是在本文描述的M5网络体系结构的基础上建模的。处理原始音频数据的模型的一个重要方面是其第一层滤波器的接受域。我们模型的第一个滤波器的长度是80，所以当处理以8kHz采样的音频时，接收场大约是10ms(而在4kHz时，大约是20ms)。这个大小类似于语音处理应用程序，通常使用20ms到40ms的接受域。"
      ],
      "metadata": {
        "id": "ISxEO96COWM0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class M5(nn.Module):\n",
        "    def __init__(self, n_input=1, n_output=35, stride=16, n_channel=32):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(n_input, n_channel, kernel_size=80, stride=stride)\n",
        "        self.bn1 = nn.BatchNorm1d(n_channel)\n",
        "        self.pool1 = nn.MaxPool1d(4)\n",
        "        self.conv2 = nn.Conv1d(n_channel, n_channel, kernel_size=3)\n",
        "        self.bn2 = nn.BatchNorm1d(n_channel)\n",
        "        self.pool2 = nn.MaxPool1d(4)\n",
        "        self.conv3 = nn.Conv1d(n_channel, 2 * n_channel, kernel_size=3)\n",
        "        self.bn3 = nn.BatchNorm1d(2 * n_channel)\n",
        "        self.pool3 = nn.MaxPool1d(4)\n",
        "        self.conv4 = nn.Conv1d(2 * n_channel, 2 * n_channel, kernel_size=3)\n",
        "        self.bn4 = nn.BatchNorm1d(2 * n_channel)\n",
        "        self.pool4 = nn.MaxPool1d(4)\n",
        "        self.fc1 = nn.Linear(2 * n_channel, n_output)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(self.bn1(x))\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(self.bn2(x))\n",
        "        x = self.pool2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = F.relu(self.bn3(x))\n",
        "        x = self.pool3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = F.relu(self.bn4(x))\n",
        "        x = self.pool4(x)\n",
        "        x = F.avg_pool1d(x, x.shape[-1])\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = self.fc1(x)\n",
        "        return F.log_softmax(x, dim=2)\n",
        "\n",
        "\n",
        "model = M5(n_input=transformed.shape[0], n_output=len(labels))\n",
        "model.to(device)\n",
        "print(model)\n",
        "\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "n = count_parameters(model)\n",
        "print(\"Number of parameters: %s\" % n)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:06:20.06919Z",
          "iopub.execute_input": "2023-11-28T02:06:20.069514Z",
          "iopub.status.idle": "2023-11-28T02:06:21.741515Z",
          "shell.execute_reply.started": "2023-11-28T02:06:20.069482Z",
          "shell.execute_reply": "2023-11-28T02:06:21.740437Z"
        },
        "trusted": true,
        "id": "SJsvQGgQOWM0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=0.0001)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)  # reduce the learning after 20 epochs by a factor of 10"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:06:21.744583Z",
          "iopub.execute_input": "2023-11-28T02:06:21.74488Z",
          "iopub.status.idle": "2023-11-28T02:06:21.750229Z",
          "shell.execute_reply.started": "2023-11-28T02:06:21.744853Z",
          "shell.execute_reply": "2023-11-28T02:06:21.749106Z"
        },
        "trusted": true,
        "id": "LjQx9RTpOWM1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, epoch, log_interval):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "\n",
        "        # apply transform and model on whole batch directly on device\n",
        "        data = transform(data)\n",
        "        output = model(data)\n",
        "\n",
        "        # negative log-likelihood for a tensor of size (batch x 1 x n_output)\n",
        "        loss = F.nll_loss(output.squeeze(), target)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print training stats\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print(f\"Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} ({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}\")\n",
        "\n",
        "        # update progress bar\n",
        "        pbar.update(pbar_update)\n",
        "        # record loss\n",
        "        losses.append(loss.item())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:06:21.75475Z",
          "iopub.execute_input": "2023-11-28T02:06:21.755038Z",
          "iopub.status.idle": "2023-11-28T02:06:21.767742Z",
          "shell.execute_reply.started": "2023-11-28T02:06:21.755013Z",
          "shell.execute_reply": "2023-11-28T02:06:21.766554Z"
        },
        "trusted": true,
        "id": "n4FFAgOkOWM1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def number_of_correct(pred, target):\n",
        "    # count number of correct predictions\n",
        "    return pred.squeeze().eq(target).sum().item()\n",
        "\n",
        "\n",
        "def get_likely_index(tensor):\n",
        "    # find most likely label index for each element in the batch\n",
        "    return tensor.argmax(dim=-1)\n",
        "\n",
        "\n",
        "def test(model, epoch):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    for data, target in test_loader:\n",
        "\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "\n",
        "        # apply transform and model on whole batch directly on device\n",
        "        data = transform(data)\n",
        "        output = model(data)\n",
        "\n",
        "        pred = get_likely_index(output)\n",
        "        correct += number_of_correct(pred, target)\n",
        "\n",
        "        # update progress bar\n",
        "        pbar.update(pbar_update)\n",
        "\n",
        "    print(f\"\\nTest Epoch: {epoch}\\tAccuracy: {correct}/{len(test_loader.dataset)} ({100. * correct / len(test_loader.dataset):.0f}%)\\n\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:06:21.768997Z",
          "iopub.execute_input": "2023-11-28T02:06:21.769354Z",
          "iopub.status.idle": "2023-11-28T02:06:21.783895Z",
          "shell.execute_reply.started": "2023-11-28T02:06:21.76932Z",
          "shell.execute_reply": "2023-11-28T02:06:21.783Z"
        },
        "trusted": true,
        "id": "RcYBf-oxOWM1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "log_interval = 20\n",
        "n_epoch = 2\n",
        "\n",
        "pbar_update = 1 / (len(train_loader) + len(test_loader))\n",
        "losses = []\n",
        "\n",
        "# The transform needs to live on the same device as the model and the data.\n",
        "transform = transform.to(device)\n",
        "with tqdm(total=n_epoch) as pbar:\n",
        "    for epoch in range(1, n_epoch + 1):\n",
        "        train(model, epoch, log_interval)\n",
        "        test(model, epoch)\n",
        "        scheduler.step()\n",
        "\n",
        "# Let's plot the training loss versus the number of iteration.\n",
        "plt.plot(losses);\n",
        "plt.title(\"training loss\");\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:06:21.785205Z",
          "iopub.execute_input": "2023-11-28T02:06:21.785555Z",
          "iopub.status.idle": "2023-11-28T02:21:26.228915Z",
          "shell.execute_reply.started": "2023-11-28T02:06:21.785506Z",
          "shell.execute_reply": "2023-11-28T02:21:26.227875Z"
        },
        "trusted": true,
        "id": "_g206ZcTOWM1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(tensor):\n",
        "    # Use the model to predict the label of the waveform\n",
        "    tensor = tensor.to(device)\n",
        "    tensor = transform(tensor)\n",
        "    tensor = model(tensor.unsqueeze(0))\n",
        "    tensor = get_likely_index(tensor)\n",
        "    tensor = index_to_label(tensor.squeeze())\n",
        "    return tensor\n",
        "\n",
        "\n",
        "waveform, sample_rate, utterance, *_ = train_set[-1]\n",
        "ipd.Audio(waveform.numpy(), rate=sample_rate)\n",
        "\n",
        "print(f\"Expected: {utterance}. Predicted: {predict(waveform)}.\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:21:26.232241Z",
          "iopub.execute_input": "2023-11-28T02:21:26.232538Z",
          "iopub.status.idle": "2023-11-28T02:21:26.253163Z",
          "shell.execute_reply.started": "2023-11-28T02:21:26.232511Z",
          "shell.execute_reply": "2023-11-28T02:21:26.252295Z"
        },
        "trusted": true,
        "id": "330otNoBOWM1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (waveform, sample_rate, utterance, *_) in enumerate(test_set):\n",
        "    output = predict(waveform)\n",
        "    if output != utterance:\n",
        "        ipd.Audio(waveform.numpy(), rate=sample_rate)\n",
        "        print(f\"Data point #{i}. Expected: {utterance}. Predicted: {output}.\")\n",
        "        break\n",
        "else:\n",
        "    print(\"All examples in this dataset were correctly classified!\")\n",
        "    print(\"In this case, let's just look at the last data point\")\n",
        "    ipd.Audio(waveform.numpy(), rate=sample_rate)\n",
        "    print(f\"Data point #{i}. Expected: {utterance}. Predicted: {output}.\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:21:26.25419Z",
          "iopub.execute_input": "2023-11-28T02:21:26.254458Z",
          "iopub.status.idle": "2023-11-28T02:21:26.27228Z",
          "shell.execute_reply.started": "2023-11-28T02:21:26.254433Z",
          "shell.execute_reply": "2023-11-28T02:21:26.271429Z"
        },
        "trusted": true,
        "id": "wDll49OcOWM2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jcjDQoQ8OWM2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rczwpAtOOWM2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZUZXDfsCOWM2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Accent recognition"
      ],
      "metadata": {
        "id": "ZDhWeo-xOWM2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#imports\n",
        "!pip install imblearn\n",
        "!pip install torch\n",
        "!pip install torchaudio\n",
        "import pandas as pd\n",
        "import gc\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "import torch\n",
        "import torchaudio\n",
        "import datasets\n",
        "import transformers\n",
        "print(transformers.__version__)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:21:26.273369Z",
          "iopub.execute_input": "2023-11-28T02:21:26.273623Z",
          "iopub.status.idle": "2023-11-28T02:21:29.540717Z",
          "shell.execute_reply.started": "2023-11-28T02:21:26.273599Z",
          "shell.execute_reply": "2023-11-28T02:21:29.539705Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEYfmAUpOWM2",
        "outputId": "07057d83-e309-41b3-945f-223aa9f75f80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imblearn in c:\\users\\master\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.0)\n",
            "Requirement already satisfied: imbalanced-learn in c:\\users\\master\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from imblearn) (0.14.0)\n",
            "Requirement already satisfied: numpy<3,>=1.25.2 in c:\\users\\master\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from imbalanced-learn->imblearn) (2.3.2)\n",
            "Requirement already satisfied: scipy<2,>=1.11.4 in c:\\users\\master\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from imbalanced-learn->imblearn) (1.16.1)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.4.2 in c:\\users\\master\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from imbalanced-learn->imblearn) (1.7.1)\n",
            "Requirement already satisfied: joblib<2,>=1.2.0 in c:\\users\\master\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from imbalanced-learn->imblearn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in c:\\users\\master\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from imbalanced-learn->imblearn) (3.6.0)\n",
            "Requirement already satisfied: torch in c:\\users\\master\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.8.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\master\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\master\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\master\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx in c:\\users\\master\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\master\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in c:\\users\\master\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\master\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\master\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: torchaudio in c:\\users\\master\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.8.0)\n",
            "Requirement already satisfied: torch==2.8.0 in c:\\users\\master\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torchaudio) (2.8.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\master\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch==2.8.0->torchaudio) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\master\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch==2.8.0->torchaudio) (4.15.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\master\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch==2.8.0->torchaudio) (1.14.0)\n",
            "Requirement already satisfied: networkx in c:\\users\\master\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch==2.8.0->torchaudio) (3.5)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\master\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch==2.8.0->torchaudio) (3.1.6)\n",
            "Requirement already satisfied: fsspec in c:\\users\\master\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch==2.8.0->torchaudio) (2025.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\master\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sympy>=1.13.3->torch==2.8.0->torchaudio) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\master\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2->torch==2.8.0->torchaudio) (3.0.2)\n",
            "4.28.1\n"
          ]
        }
      ],
      "execution_count": 14
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# If you already downloaded earlier, reuse that; otherwise download now\n",
        "try:\n",
        "    cv_root = Path(mozillaorg_common_voice_path)\n",
        "except NameError:\n",
        "    import kagglehub\n",
        "    cv_root = Path(kagglehub.dataset_download('mozillaorg/common-voice'))\n",
        "\n",
        "print(\"📁 Common Voice root:\", cv_root)\n",
        "\n",
        "def _find_one(root: Path, names):\n",
        "    cands = []\n",
        "    for n in names:\n",
        "        cands += list(root.rglob(n))\n",
        "    # prefer shortest path (usually top-level) and deterministic order\n",
        "    cands = sorted(cands, key=lambda p: (len(p.parts), str(p).lower()))\n",
        "    return cands[0] if cands else None\n",
        "\n",
        "# Prefer the higher-quality validated/train split; keep test apart\n",
        "train_like_names = [\n",
        "    \"cv-valid-train.csv\",\"cv-valid-train.tsv\",\n",
        "    \"validated.csv\",\"validated.tsv\",\n",
        "    \"train.csv\",\"train.tsv\"\n",
        "]\n",
        "test_like_names = [\n",
        "    \"cv-test.csv\",\"cv-test.tsv\",\"test.csv\",\"test.tsv\"\n",
        "]\n",
        "\n",
        "train_meta = _find_one(cv_root, train_like_names)\n",
        "test_meta  = _find_one(cv_root, test_like_names)\n",
        "\n",
        "if not train_meta:\n",
        "    raise FileNotFoundError(\n",
        "        f\"Could not find any of {train_like_names} under {cv_root}. \"\n",
        "        \"Inspect the folder to see available metadata files.\"\n",
        "    )\n",
        "\n",
        "def _load_meta(path: Path) -> pd.DataFrame:\n",
        "    sep = \"\\t\" if path.suffix.lower() == \".tsv\" else \",\"\n",
        "    df = pd.read_csv(path, sep=sep)\n",
        "    # normalize columns that often appear in Common Voice\n",
        "    df.columns = [c.strip() for c in df.columns]\n",
        "    return df\n",
        "\n",
        "dd = _load_meta(train_meta).drop_duplicates()\n",
        "print(f\"✅ Loaded TRAIN/VALID meta: {train_meta}  -> shape {dd.shape}\")\n",
        "\n",
        "# Keep only rows with non-null 'accent' if present (some releases may miss it)\n",
        "if \"accent\" in dd.columns:\n",
        "    dd = dd[dd[\"accent\"].notna()].copy()\n",
        "    print(\"🎯 Filtered non-null 'accent':\", dd.shape)\n",
        "else:\n",
        "    print(\"⚠️ No 'accent' column in this release. Available columns:\", list(dd.columns))\n",
        "\n",
        "# Leave TEST set apart if available\n",
        "if test_meta:\n",
        "    test_df = _load_meta(test_meta).drop_duplicates()\n",
        "    print(f\"📦 Loaded TEST meta: {test_meta} -> shape {test_df.shape}\")\n",
        "else:\n",
        "    test_df = None\n",
        "    print(\"ℹ️ No explicit TEST file found; you can hold out a split from train if needed.\")\n",
        "\n",
        "# Optional: make a validation split from dd (stratify on 'accent' if present)\n",
        "if \"accent\" in dd.columns:\n",
        "    train_df, val_df = train_test_split(\n",
        "        dd, test_size=0.1, random_state=42, stratify=dd[\"accent\"]\n",
        "    )\n",
        "else:\n",
        "    train_df, val_df = train_test_split(dd, test_size=0.1, random_state=42)\n",
        "\n",
        "print(\"📊 Final splits:\",\n",
        "      f\"\\n  train: {train_df.shape}\",\n",
        "      f\"\\n  valid: {val_df.shape}\",\n",
        "      f\"\\n  test : {None if test_df is None else test_df.shape}\")\n",
        "\n",
        "# Peek\n",
        "display(train_df.sample(min(5, len(train_df))) if len(train_df) else train_df.head())\n"
      ],
      "metadata": {
        "id": "tBoFgUTuoDTZ",
        "outputId": "1932b8aa-15f4-4662-f3c9-f62175c40837",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📁 Common Voice root: C:\\Users\\MASTER\\.cache\\kagglehub\\datasets\\mozillaorg\\common-voice\\versions\\2\n",
            "✅ Loaded TRAIN/VALID meta: C:\\Users\\MASTER\\.cache\\kagglehub\\datasets\\mozillaorg\\common-voice\\versions\\2\\cv-valid-train.csv  -> shape (195776, 8)\n",
            "🎯 Filtered non-null 'accent': (64711, 8)\n",
            "ℹ️ No explicit TEST file found; you can hold out a split from train if needed.\n",
            "📊 Final splits: \n",
            "  train: (58239, 8) \n",
            "  valid: (6472, 8) \n",
            "  test : None\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                filename  \\\n",
              "84436   cv-valid-train/sample-084436.mp3   \n",
              "156304  cv-valid-train/sample-156304.mp3   \n",
              "150834  cv-valid-train/sample-150834.mp3   \n",
              "123801  cv-valid-train/sample-123801.mp3   \n",
              "42956   cv-valid-train/sample-042956.mp3   \n",
              "\n",
              "                                                     text  up_votes  \\\n",
              "84436   i need you to be spontaneous he asked me out t...         2   \n",
              "156304  the alchemist dismounted slowly and the boy di...         3   \n",
              "150834  never advertise razors by shaving a monkey it'...         1   \n",
              "123801  i'm going to become bitter and distrustful of ...         3   \n",
              "42956                  that doesn't happen to just anyone         1   \n",
              "\n",
              "        down_votes       age  gender  accent  duration  \n",
              "84436            1  thirties  female      us       NaN  \n",
              "156304           0  twenties  female  indian       NaN  \n",
              "150834           0  twenties    male      us       NaN  \n",
              "123801           0  fourties    male      us       NaN  \n",
              "42956            0  twenties    male      us       NaN  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>text</th>\n",
              "      <th>up_votes</th>\n",
              "      <th>down_votes</th>\n",
              "      <th>age</th>\n",
              "      <th>gender</th>\n",
              "      <th>accent</th>\n",
              "      <th>duration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>84436</th>\n",
              "      <td>cv-valid-train/sample-084436.mp3</td>\n",
              "      <td>i need you to be spontaneous he asked me out t...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>thirties</td>\n",
              "      <td>female</td>\n",
              "      <td>us</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156304</th>\n",
              "      <td>cv-valid-train/sample-156304.mp3</td>\n",
              "      <td>the alchemist dismounted slowly and the boy di...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>twenties</td>\n",
              "      <td>female</td>\n",
              "      <td>indian</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150834</th>\n",
              "      <td>cv-valid-train/sample-150834.mp3</td>\n",
              "      <td>never advertise razors by shaving a monkey it'...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>twenties</td>\n",
              "      <td>male</td>\n",
              "      <td>us</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123801</th>\n",
              "      <td>cv-valid-train/sample-123801.mp3</td>\n",
              "      <td>i'm going to become bitter and distrustful of ...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>fourties</td>\n",
              "      <td>male</td>\n",
              "      <td>us</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42956</th>\n",
              "      <td>cv-valid-train/sample-042956.mp3</td>\n",
              "      <td>that doesn't happen to just anyone</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>twenties</td>\n",
              "      <td>male</td>\n",
              "      <td>us</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dd = pd.read_csv(\n",
        "    r\"C:\\Users\\MASTER\\.cache\\kagglehub\\datasets\\mozillaorg\\common-voice\\versions\\2\\cv-valid-train.csv\"\n",
        ").drop_duplicates()\n",
        "dd = dd[dd['accent'].notna()]\n",
        "print(dd.shape)\n",
        "dd.sample(5)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:21:29.542206Z",
          "iopub.execute_input": "2023-11-28T02:21:29.543286Z",
          "iopub.status.idle": "2023-11-28T02:21:30.430909Z",
          "shell.execute_reply.started": "2023-11-28T02:21:29.543245Z",
          "shell.execute_reply": "2023-11-28T02:21:30.429963Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "MnNE__plOWM2",
        "outputId": "250c89be-7f6a-4a69-c2fa-951b47207d67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64711, 8)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                filename  \\\n",
              "95467   cv-valid-train/sample-095467.mp3   \n",
              "87032   cv-valid-train/sample-087032.mp3   \n",
              "163899  cv-valid-train/sample-163899.mp3   \n",
              "39647   cv-valid-train/sample-039647.mp3   \n",
              "87298   cv-valid-train/sample-087298.mp3   \n",
              "\n",
              "                                                     text  up_votes  \\\n",
              "95467                             i thought you were gone         2   \n",
              "87032             plastic surgery has become more popular         1   \n",
              "163899         and he immediately felt peace in his heart         3   \n",
              "39647                             she doesn't know it yet         1   \n",
              "87298   one day the earth began to tremble and the nil...         1   \n",
              "\n",
              "        down_votes       age  gender     accent  duration  \n",
              "95467            0  fourties    male         us       NaN  \n",
              "87032            0  twenties    male  australia       NaN  \n",
              "163899           0     teens    male    england       NaN  \n",
              "39647            0   fifties  female     indian       NaN  \n",
              "87298            0  thirties    male     canada       NaN  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>text</th>\n",
              "      <th>up_votes</th>\n",
              "      <th>down_votes</th>\n",
              "      <th>age</th>\n",
              "      <th>gender</th>\n",
              "      <th>accent</th>\n",
              "      <th>duration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>95467</th>\n",
              "      <td>cv-valid-train/sample-095467.mp3</td>\n",
              "      <td>i thought you were gone</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>fourties</td>\n",
              "      <td>male</td>\n",
              "      <td>us</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87032</th>\n",
              "      <td>cv-valid-train/sample-087032.mp3</td>\n",
              "      <td>plastic surgery has become more popular</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>twenties</td>\n",
              "      <td>male</td>\n",
              "      <td>australia</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>163899</th>\n",
              "      <td>cv-valid-train/sample-163899.mp3</td>\n",
              "      <td>and he immediately felt peace in his heart</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>teens</td>\n",
              "      <td>male</td>\n",
              "      <td>england</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39647</th>\n",
              "      <td>cv-valid-train/sample-039647.mp3</td>\n",
              "      <td>she doesn't know it yet</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>fifties</td>\n",
              "      <td>female</td>\n",
              "      <td>indian</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87298</th>\n",
              "      <td>cv-valid-train/sample-087298.mp3</td>\n",
              "      <td>one day the earth began to tremble and the nil...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>thirties</td>\n",
              "      <td>male</td>\n",
              "      <td>canada</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ],
      "execution_count": 99
    },
    {
      "cell_type": "code",
      "source": [
        "dd['accent'].value_counts()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:21:30.432166Z",
          "iopub.execute_input": "2023-11-28T02:21:30.43243Z",
          "iopub.status.idle": "2023-11-28T02:21:30.449785Z",
          "shell.execute_reply.started": "2023-11-28T02:21:30.432406Z",
          "shell.execute_reply": "2023-11-28T02:21:30.448845Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LB0QU4XOWM2",
        "outputId": "efeca948-2f67-4db5-b3d9-478a90353ce2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "accent\n",
              "us                30997\n",
              "england           14938\n",
              "indian             4490\n",
              "australia          4287\n",
              "canada             3901\n",
              "scotland           1556\n",
              "african            1173\n",
              "newzealand         1153\n",
              "ireland             944\n",
              "philippines         326\n",
              "wales               262\n",
              "bermuda             196\n",
              "malaysia            182\n",
              "singapore           124\n",
              "hongkong             99\n",
              "southatlandtic       83\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "execution_count": 16
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "labels = [lang for lang, _ in Counter(dd['accent']).most_common(5)]\n",
        "labels"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:21:30.451243Z",
          "iopub.execute_input": "2023-11-28T02:21:30.451965Z",
          "iopub.status.idle": "2023-11-28T02:21:30.473888Z",
          "shell.execute_reply.started": "2023-11-28T02:21:30.451927Z",
          "shell.execute_reply": "2023-11-28T02:21:30.473006Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OIUtvq5OWM2",
        "outputId": "d5f162fe-fe6f-4f1e-ffb6-bfa582d951e7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['us', 'england', 'indian', 'australia', 'canada']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "execution_count": 17
    },
    {
      "cell_type": "code",
      "source": [
        "RATE_HZ = 16000 # resampling rate in Hz\n",
        "MAX_LENGTH = 40000 # maximum audio interval length to consider (= RATE_HZ * SECONDS)\n",
        "label2id, id2label = dict(), dict()\n",
        "for i, label in enumerate(labels):\n",
        "    label2id[label] = i\n",
        "    id2label[i] = label\n",
        "\n",
        "print(id2label, '\\n\\n', label2id)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:21:30.475004Z",
          "iopub.execute_input": "2023-11-28T02:21:30.475349Z",
          "iopub.status.idle": "2023-11-28T02:21:30.485603Z",
          "shell.execute_reply.started": "2023-11-28T02:21:30.475313Z",
          "shell.execute_reply": "2023-11-28T02:21:30.484823Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KK5NtACOOWM2",
        "outputId": "0ef64ca7-c89f-498f-a5d2-74055b4c4d7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'us', 1: 'england', 2: 'indian', 3: 'australia', 4: 'canada'} \n",
            "\n",
            " {'us': 0, 'england': 1, 'indian': 2, 'australia': 3, 'canada': 4}\n"
          ]
        }
      ],
      "execution_count": 18
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load and preprocess data"
      ],
      "metadata": {
        "id": "RWvSiWZGOWM3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dd = dd[dd['accent'].isin(labels)]\n",
        "dd['label'] = dd['accent'].apply(lambda x: label2id[x])\n",
        "dd = dd[['filename', 'label']]\n",
        "print(dd.shape)\n",
        "dd.sample(5)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:21:30.486697Z",
          "iopub.execute_input": "2023-11-28T02:21:30.487009Z",
          "iopub.status.idle": "2023-11-28T02:21:30.556789Z",
          "shell.execute_reply.started": "2023-11-28T02:21:30.486982Z",
          "shell.execute_reply": "2023-11-28T02:21:30.555847Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "5xU4GENHOWM3",
        "outputId": "7404bf1f-a510-4506-dc33-458a407073e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(58613, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                filename  label\n",
              "23351   cv-valid-train/sample-023351.mp3      0\n",
              "143117  cv-valid-train/sample-143117.mp3      3\n",
              "178567  cv-valid-train/sample-178567.mp3      4\n",
              "195766  cv-valid-train/sample-195766.mp3      1\n",
              "159266  cv-valid-train/sample-159266.mp3      0"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>23351</th>\n",
              "      <td>cv-valid-train/sample-023351.mp3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143117</th>\n",
              "      <td>cv-valid-train/sample-143117.mp3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178567</th>\n",
              "      <td>cv-valid-train/sample-178567.mp3</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195766</th>\n",
              "      <td>cv-valid-train/sample-195766.mp3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159266</th>\n",
              "      <td>cv-valid-train/sample-159266.mp3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "execution_count": 19
    },
    {
      "cell_type": "code",
      "source": [
        "# random undersampling of all but minority class\n",
        "rus = RandomUnderSampler(random_state=83, sampling_strategy='not minority')\n",
        "y = dd[['label']]\n",
        "dd = dd.drop(['label'], axis=1)\n",
        "dd, y_resampled = rus.fit_resample(dd, y)\n",
        "del y\n",
        "dd['label'] = y_resampled\n",
        "del y_resampled\n",
        "gc.collect()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:21:30.557892Z",
          "iopub.execute_input": "2023-11-28T02:21:30.558198Z",
          "iopub.status.idle": "2023-11-28T02:21:30.794835Z",
          "shell.execute_reply.started": "2023-11-28T02:21:30.558172Z",
          "shell.execute_reply": "2023-11-28T02:21:30.793885Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dwEz6a4OWM3",
        "outputId": "41aaeb6b-3c20-4fbb-efa1-0612a717078e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "986"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "execution_count": 20
    },
    {
      "cell_type": "code",
      "source": [
        "dd['label'].value_counts()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:21:30.796258Z",
          "iopub.execute_input": "2023-11-28T02:21:30.796915Z",
          "iopub.status.idle": "2023-11-28T02:21:30.804468Z",
          "shell.execute_reply.started": "2023-11-28T02:21:30.796877Z",
          "shell.execute_reply": "2023-11-28T02:21:30.803443Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekiCgoseOWM3",
        "outputId": "6b51cc64-e70e-4ada-8db8-59c2392af300"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label\n",
              "0    30997\n",
              "1    14938\n",
              "2     4490\n",
              "3     4287\n",
              "4     3901\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "execution_count": 10
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 1) Build an index of all audio files under cv_root (mp3 + wav just in case)\n",
        "audio_paths = list(cv_root.rglob(\"*.mp3\")) + list(cv_root.rglob(\"*.wav\"))\n",
        "print(f\"Found {len(audio_paths)} audio files under {cv_root}\")\n",
        "\n",
        "# 2) Map basename -> full path (lowercased for safety)\n",
        "index = {p.name.lower(): str(p.resolve()) for p in audio_paths}\n",
        "\n",
        "# 3) Add a 'basename' column derived from metadata's filename\n",
        "dd['basename'] = dd['filename'].apply(lambda s: Path(str(s)).name.lower())\n",
        "\n",
        "# 4) Map to absolute paths via the index\n",
        "dd['abs_path'] = dd['basename'].map(index)\n",
        "\n",
        "# 5) Report missing and drop them\n",
        "missing = dd['abs_path'].isna().sum()\n",
        "print(f\"Resolved: {len(dd) - missing}/{len(dd)} | Missing: {missing}\")\n",
        "\n",
        "# (Optional) peek a few missing basenames to understand gaps\n",
        "if missing:\n",
        "    print(\"Missing examples:\", dd.loc[dd['abs_path'].isna(), 'basename'].head(5).tolist())\n",
        "\n",
        "# Keep only rows we can actually read\n",
        "dd = dd.dropna(subset=['abs_path']).copy()\n"
      ],
      "metadata": {
        "id": "grsu2VWt8qry",
        "outputId": "76dd7ebb-b371-4241-980d-b6a49c658d00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 380368 audio files under C:\\Users\\MASTER\\.cache\\kagglehub\\datasets\\mozillaorg\\common-voice\\versions\\2\n",
            "Resolved: 64711/64711 | Missing: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import os, numpy as np, torch, torchaudio\n",
        "\n",
        "# --- 1) Point pydub to your FFmpeg binaries (no PATH fiddling needed) ---\n",
        "from pydub import AudioSegment\n",
        "AudioSegment.converter = r\"C:\\Program Files\\FFmpeg\\bin\\ffmpeg.exe\"\n",
        "AudioSegment.ffprobe   = r\"C:\\Program Files\\FFmpeg\\bin\\ffprobe.exe\"\n",
        "\n",
        "# (Optional) also add to PATH for other libs that rely on PATH lookups\n",
        "ffbin = r\"C:\\Program Files\\FFmpeg\\bin\"\n",
        "if ffbin not in os.environ.get(\"PATH\",\"\"):\n",
        "    os.environ[\"PATH\"] = os.environ[\"PATH\"] + \";\" + ffbin\n",
        "\n",
        "def _resample_torch(wav: torch.Tensor, orig_sr: int, target_sr: int) -> torch.Tensor:\n",
        "    if orig_sr == target_sr:\n",
        "        return wav\n",
        "    return torchaudio.transforms.Resample(orig_sr, target_sr)(wav)\n",
        "\n",
        "def _resample_numpy(x: np.ndarray, orig_sr: int, target_sr: int) -> np.ndarray:\n",
        "    try:\n",
        "        from scipy.signal import resample_poly\n",
        "        up, down = target_sr, orig_sr\n",
        "        return np.stack([resample_poly(ch, up, down) for ch in x], axis=0)\n",
        "    except Exception:\n",
        "        ratio = target_sr / orig_sr\n",
        "        t_new = np.arange(int(x.shape[1] * ratio))\n",
        "        t_old = np.linspace(0, x.shape[1]-1, x.shape[1])\n",
        "        return np.stack([np.interp(t_new, t_old, ch) for ch in x], axis=0).astype(np.float32)\n",
        "\n",
        "def load_audio_any(path: str, target_sr: int = 16000, mono: bool = True):\n",
        "    \"\"\"Try torchaudio first; fallback to pydub+FFmpeg.\"\"\"\n",
        "    # --- torchaudio first ---\n",
        "    try:\n",
        "        wav, sr = torchaudio.load(path)\n",
        "        if not torch.is_floating_point(wav):\n",
        "            wav = wav.float() / (1 << 31)\n",
        "        if mono and wav.shape[0] > 1:\n",
        "            wav = wav.mean(dim=0, keepdim=True)\n",
        "        wav = _resample_torch(wav, sr, target_sr)\n",
        "        return wav.contiguous(), target_sr\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    # --- fallback: pydub (uses the FFmpeg paths set above) ---\n",
        "    seg = AudioSegment.from_file(path)   # auto-detect via extension\n",
        "    sr = seg.frame_rate\n",
        "    ch = seg.channels\n",
        "    sw = seg.sample_width  # bytes/sample\n",
        "\n",
        "    samples = np.array(seg.get_array_of_samples())\n",
        "    if ch > 1:\n",
        "        samples = samples.reshape((-1, ch)).T  # [C, T]\n",
        "    else:\n",
        "        samples = samples[None, :]            # [1, T]\n",
        "\n",
        "    max_val = float(1 << (8*sw - 1))          # normalize to [-1, 1]\n",
        "    samples = (samples.astype(np.float32) / max_val)\n",
        "\n",
        "    if sr != target_sr:\n",
        "        samples = _resample_numpy(samples, sr, target_sr)\n",
        "\n",
        "    wav = torch.from_numpy(samples.astype(np.float32))\n",
        "    if mono and wav.shape[0] > 1:\n",
        "        wav = wav.mean(dim=0, keepdim=True)\n",
        "    return wav.contiguous(), target_sr\n",
        "\n",
        "# --- 2) Use the resolved local path we built earlier ---\n",
        "file_path = dd['abs_path'].iloc[0]\n",
        "print(\"Loading:\", file_path, \"| exists:\", Path(file_path).exists())\n",
        "\n",
        "audio, rate = load_audio_any(file_path, target_sr=16000, mono=True)\n",
        "print(\"✅ Loaded\")\n",
        "print(\"   Shape:\", tuple(audio.shape), \"| SR:\", rate)\n"
      ],
      "metadata": {
        "id": "hadydHDy7nfL",
        "outputId": "175c775a-2413-4825-f3ac-d2c41ef64e9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading: C:\\Users\\MASTER\\.cache\\kagglehub\\datasets\\mozillaorg\\common-voice\\versions\\2\\cv-valid-train\\cv-valid-train\\sample-000005.mp3 | exists: True\n",
            "✅ Loaded\n",
            "   Shape: (1, 93312) | SR: 16000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# audio, rate already = (waveform, RATE_HZ) from load_audio_any\n",
        "audio = audio.numpy().reshape(-1)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:21:30.866979Z",
          "iopub.execute_input": "2023-11-28T02:21:30.867792Z",
          "iopub.status.idle": "2023-11-28T02:21:30.873036Z",
          "shell.execute_reply.started": "2023-11-28T02:21:30.867752Z",
          "shell.execute_reply": "2023-11-28T02:21:30.872116Z"
        },
        "trusted": true,
        "id": "dDm9fDwoOWM3"
      },
      "outputs": [],
      "execution_count": 106
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure mono [T] NumPy array regardless of how audio is shaped\n",
        "if isinstance(audio, torch.Tensor):\n",
        "    if audio.ndim == 2 and audio.shape[0] == 1:   # [1, T]\n",
        "        audio_np = audio.squeeze(0).numpy()\n",
        "    elif audio.ndim == 2 and audio.shape[0] > 1:  # [C, T] -> average to mono\n",
        "        audio_np = audio.mean(dim=0).numpy()\n",
        "    else:  # already [T]\n",
        "        audio_np = audio.numpy()\n",
        "else:\n",
        "    # already NumPy\n",
        "    audio_np = audio\n",
        "\n",
        "print(\"Final shape:\", audio_np.shape)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:21:30.874254Z",
          "iopub.execute_input": "2023-11-28T02:21:30.874602Z",
          "iopub.status.idle": "2023-11-28T02:21:30.885618Z",
          "shell.execute_reply.started": "2023-11-28T02:21:30.874567Z",
          "shell.execute_reply": "2023-11-28T02:21:30.884833Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgdawQEVOWM3",
        "outputId": "1c6fce20-8b5f-4a43-b9ca-3084c5a1c674"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final shape: (93312,)\n"
          ]
        }
      ],
      "execution_count": 108
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def get_transform_audio(file):\n",
        "    # use the resolved absolute path from dd\n",
        "    file_path = dd.loc[file, 'abs_path'] if isinstance(file, (int, np.integer)) else file\n",
        "    if Path(str(file_path)).exists():\n",
        "        audio, rate = load_audio_any(file_path, target_sr=RATE_HZ, mono=True)\n",
        "    else:\n",
        "        raise FileNotFoundError(f\"File not found: {file_path}\")\n",
        "\n",
        "    # Ensure 1-D numpy waveform\n",
        "    if isinstance(audio, torch.Tensor):\n",
        "        if audio.ndim == 2 and audio.shape[0] > 1:  # stereo -> mono\n",
        "            audio = audio.mean(dim=0)\n",
        "        else:\n",
        "            audio = audio.squeeze()\n",
        "        audio_np = audio.numpy()\n",
        "    else:\n",
        "        audio_np = np.array(audio, dtype=np.float32)\n",
        "\n",
        "    # Truncate/pad to fixed MAX_LENGTH\n",
        "    audio_np = audio_np[:MAX_LENGTH]\n",
        "    return audio_np\n",
        "\n",
        "# Apply to all rows with progress bar\n",
        "tqdm.pandas()\n",
        "dd['audio'] = dd['abs_path'].progress_apply(get_transform_audio)\n",
        "gc.collect()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:21:30.886963Z",
          "iopub.execute_input": "2023-11-28T02:21:30.887517Z",
          "iopub.status.idle": "2023-11-28T02:28:32.570348Z",
          "shell.execute_reply.started": "2023-11-28T02:21:30.887481Z",
          "shell.execute_reply": "2023-11-28T02:28:32.569363Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rOq_SWzOWNB",
        "outputId": "d725660b-44b7-46b1-bd45-51cb372f39ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 64711/64711 [2:38:42<00:00,  6.80it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1154"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ],
      "execution_count": 109
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "dd = dd.drop(['filename'], axis=1)\n",
        "gc.collect()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:28:32.571768Z",
          "iopub.execute_input": "2023-11-28T02:28:32.572646Z",
          "iopub.status.idle": "2023-11-28T02:28:32.794948Z",
          "shell.execute_reply.started": "2023-11-28T02:28:32.572598Z",
          "shell.execute_reply": "2023-11-28T02:28:32.794042Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drVchiH8OWNB",
        "outputId": "19757521-3399-4f92-b407-21d3225f8ef8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: total: 250 ms\n",
            "Wall time: 242 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4257"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ],
      "execution_count": 85
    },
    {
      "cell_type": "code",
      "source": [
        "dd.sample(5)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:28:32.800794Z",
          "iopub.execute_input": "2023-11-28T02:28:32.801109Z",
          "iopub.status.idle": "2023-11-28T02:28:32.823465Z",
          "shell.execute_reply.started": "2023-11-28T02:28:32.801074Z",
          "shell.execute_reply": "2023-11-28T02:28:32.822415Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "r9B6NobeOWNC",
        "outputId": "2f84b2d0-6136-4700-84fe-c61db697f4b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        label                                           abs_path\n",
              "132405      1  C:\\Users\\MASTER\\.cache\\kagglehub\\datasets\\mozi...\n",
              "103549      3  C:\\Users\\MASTER\\.cache\\kagglehub\\datasets\\mozi...\n",
              "192911      3  C:\\Users\\MASTER\\.cache\\kagglehub\\datasets\\mozi...\n",
              "91054       1  C:\\Users\\MASTER\\.cache\\kagglehub\\datasets\\mozi...\n",
              "60879       4  C:\\Users\\MASTER\\.cache\\kagglehub\\datasets\\mozi..."
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>abs_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>132405</th>\n",
              "      <td>1</td>\n",
              "      <td>C:\\Users\\MASTER\\.cache\\kagglehub\\datasets\\mozi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103549</th>\n",
              "      <td>3</td>\n",
              "      <td>C:\\Users\\MASTER\\.cache\\kagglehub\\datasets\\mozi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192911</th>\n",
              "      <td>3</td>\n",
              "      <td>C:\\Users\\MASTER\\.cache\\kagglehub\\datasets\\mozi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91054</th>\n",
              "      <td>1</td>\n",
              "      <td>C:\\Users\\MASTER\\.cache\\kagglehub\\datasets\\mozi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60879</th>\n",
              "      <td>4</td>\n",
              "      <td>C:\\Users\\MASTER\\.cache\\kagglehub\\datasets\\mozi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ],
      "execution_count": 86
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "dd = Dataset.from_pandas(dd)\n",
        "gc.collect()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:28:32.82485Z",
          "iopub.execute_input": "2023-11-28T02:28:32.825197Z",
          "iopub.status.idle": "2023-11-28T02:28:48.157622Z",
          "shell.execute_reply.started": "2023-11-28T02:28:32.825168Z",
          "shell.execute_reply": "2023-11-28T02:28:48.156669Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FygyoIDKOWNC",
        "outputId": "e22d9978-be6b-4a0c-94bb-18fdf98b3086"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ],
      "execution_count": 87
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "Counter(dd['label']).items()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:28:48.159369Z",
          "iopub.execute_input": "2023-11-28T02:28:48.159662Z",
          "iopub.status.idle": "2023-11-28T02:28:48.182526Z",
          "shell.execute_reply.started": "2023-11-28T02:28:48.159634Z",
          "shell.execute_reply": "2023-11-28T02:28:48.181695Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gii4u0WlOWNC",
        "outputId": "50ab4b6e-70b1-4778-dae0-1386354fe749"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_items([(0, 3901), (1, 3901), (2, 3901), (3, 3901), (4, 3901)])"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ],
      "execution_count": 88
    },
    {
      "cell_type": "code",
      "source": [
        "dd = dd.train_test_split(test_size=0.25)\n",
        "gc.collect()\n",
        "dd"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:28:48.183916Z",
          "iopub.execute_input": "2023-11-28T02:28:48.184217Z",
          "iopub.status.idle": "2023-11-28T02:28:48.418473Z",
          "shell.execute_reply.started": "2023-11-28T02:28:48.18419Z",
          "shell.execute_reply": "2023-11-28T02:28:48.417534Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5aY7l6gOWNC",
        "outputId": "2c344248-7860-429c-ca0b-001791df50af"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['label', 'abs_path', '__index_level_0__'],\n",
              "        num_rows: 14628\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['label', 'abs_path', '__index_level_0__'],\n",
              "        num_rows: 4877\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ],
      "execution_count": 89
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load facebook/wav2vec2-base-960h model"
      ],
      "metadata": {
        "id": "MIl7WeUlOWNC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from transformers import (\n",
        "    AutoProcessor, AutoFeatureExtractor,\n",
        "    Wav2Vec2Config, Wav2Vec2ForSequenceClassification\n",
        ")\n",
        "\n",
        "# -------- Local-friendly settings --------\n",
        "MODEL_NAME = \"facebook/wav2vec2-base-960h\"   # base acoustic model\n",
        "# Use a stable local cache folder (adjust if you like)\n",
        "os.environ.setdefault(\"HF_HOME\", r\"C:\\Users\\MASTER\\.cache\\huggingface\")\n",
        "os.environ.setdefault(\"TRANSFORMERS_CACHE\", r\"C:\\Users\\MASTER\\.cache\\huggingface\\hub\")\n",
        "\n",
        "# label maps you already created earlier\n",
        "# labels, label2id, id2label must exist\n",
        "num_labels = len(labels)\n",
        "\n",
        "# -------- Processor / feature extractor --------\n",
        "# Prefer AutoProcessor (new API), fall back to AutoFeatureExtractor if needed\n",
        "try:\n",
        "    processor = AutoProcessor.from_pretrained(MODEL_NAME)\n",
        "except Exception:\n",
        "    processor = AutoFeatureExtractor.from_pretrained(MODEL_NAME)\n",
        "\n",
        "# -------- Config tailored to accent classification --------\n",
        "config = Wav2Vec2Config.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=num_labels,\n",
        "    label2id=label2id,\n",
        "    id2label=id2label,\n",
        "    finetuning_task=\"accent-classification\",\n",
        "    problem_type=\"single_label_classification\"\n",
        ")\n",
        "\n",
        "# -------- Model with classification head --------\n",
        "# ignore_mismatched_sizes=True lets us reuse the base encoder\n",
        "# even though the classifier head shape is new.\n",
        "model = Wav2Vec2ForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    config=config,\n",
        "    ignore_mismatched_sizes=True\n",
        ")\n",
        "\n",
        "# (Optional) freeze the base to warm up the classifier first\n",
        "FREEZE_BASE = False  # set to True to train only the classifier layer first\n",
        "if FREEZE_BASE:\n",
        "    for p in model.wav2vec2.parameters():\n",
        "        p.requires_grad = False\n",
        "\n",
        "# Count trainable params (in millions)\n",
        "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad) / 1e6\n",
        "print(f\"Trainable params: {trainable:.3f} M\")\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:28:48.420009Z",
          "iopub.execute_input": "2023-11-28T02:28:48.420335Z",
          "iopub.status.idle": "2023-11-28T02:28:53.134833Z",
          "shell.execute_reply.started": "2023-11-28T02:28:48.420308Z",
          "shell.execute_reply": "2023-11-28T02:28:53.133928Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141,
          "referenced_widgets": [
            "43fff3addb1c4f97bedfef3331b914b0",
            "5bfd75b4007c4eae9ba11139748a41d0",
            "fa0a05507d024132995d08144f0c630d",
            "9a6f53133f6a49ab968e19e42f731e1a",
            "28d93d220efc47e7ac3403976fb28079",
            "092c4afc0c024ff9bff657469d34c9e4",
            "797f47e7d3c242228a043311bf4c8854",
            "d0ed071742f64254a802206e37badf01",
            "c946eeb8ed0c4ea380e95ce8cefd3f26",
            "7c58587daab2479b9c5752512c01688a",
            "c51a8075383d405f8ad00812fc80c5ed",
            "f7f5ddce48f748159a4c337230cb05af",
            "1b2853d9c33c4d9baab1f45acecb3fbf",
            "ab2549ff2b92436c8d0d85c752db9af4",
            "3ada43269cc84c6ba4d3c76b97a7286a",
            "f045e1ad135144d799caf6aae6d16b13",
            "8b939defa0844ad4ba3bb5161dd944ec",
            "39d147ff0632421fbaae38fa1e65dd50",
            "fa6bfad4cb2346589aaf1d600f1d5da5",
            "f1c8390f4b8c4e9482ad4d7d9b019b1a",
            "7964549138f7470a9d3d1112df941731",
            "3fa44b3037624f7db640932d621496a0",
            "4428b9bd5f954d1388615638438c946c",
            "fa103171dd2b4ed4a5b23b5f79f42b17",
            "0ed9dd8aec9f4a098ede3869b74172d6",
            "bda73b23cf40490fb44b4582482fd4d0",
            "c9e4b898ec7d4f069e72324dcaa63135",
            "1a77ee2311c14b7ab4fb017d0652f1e0",
            "bc0307c247454b238d07420c383f6350",
            "e747f27158654236ba3f6f27d5c88f71",
            "d59ce1e0e67c4e57934e0ce65f00cdd2",
            "140b3e16d7bf4fd9bbdaa7bfd49612cd",
            "e0e1356f45e0493b899c16e53db7e021"
          ]
        },
        "id": "ftwTWIQuOWNC",
        "outputId": "54df1746-9023-444e-9a6a-56b55bd96e17"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/163 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "43fff3addb1c4f97bedfef3331b914b0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/291 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f7f5ddce48f748159a4c337230cb05af"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4428b9bd5f954d1388615638438c946c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at facebook/wav2vec2-base-960h were not used when initializing Wav2Vec2ForSequenceClassification: ['lm_head.bias', 'lm_head.weight']\n",
            "- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['classifier.weight', 'projector.bias', 'projector.weight', 'wav2vec2.masked_spec_embed', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable params: 94.570 M\n"
          ]
        }
      ],
      "execution_count": 116
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(batch):\n",
        "    inputs = feature_extractor(batch['audio'], sampling_rate=RATE_HZ, max_length=MAX_LENGTH, truncation=True)\n",
        "    inputs['input_values'] = inputs['input_values'][0]\n",
        "    return inputs\n",
        "\n",
        "dd['train'] = dd['train'].map(preprocess_function, remove_columns=\"audio\", batched=False)\n",
        "gc.collect()\n",
        "dd['test'] = dd['test'].map(preprocess_function, remove_columns=\"audio\", batched=False)\n",
        "gc.collect()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:28:53.136323Z",
          "iopub.execute_input": "2023-11-28T02:28:53.136963Z",
          "iopub.status.idle": "2023-11-28T02:38:57.958798Z",
          "shell.execute_reply.started": "2023-11-28T02:28:53.136924Z",
          "shell.execute_reply": "2023-11-28T02:38:57.957802Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wXy9pq5OOWNC",
        "outputId": "67dc23b0-8d10-4c45-dfd0-80c81d37cb64"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "preprocess_function() got an unexpected keyword argument 'remove_columns'",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[122]\u001b[39m\u001b[32m, line 37\u001b[39m\n\u001b[32m     34\u001b[39m     dd = dd.train_test_split(test_size=\u001b[32m0.25\u001b[39m)\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# Apply preprocessing\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m dd = \u001b[43mdd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocess_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremove_columns\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mabs_path\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# Format for torch\u001b[39;00m\n\u001b[32m     40\u001b[39m dd.set_format(\u001b[38;5;28mtype\u001b[39m=\u001b[33m\"\u001b[39m\u001b[33mtorch\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\frame.py:10475\u001b[39m, in \u001b[36mDataFrame.map\u001b[39m\u001b[34m(self, func, na_action, **kwargs)\u001b[39m\n\u001b[32m  10472\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minfer\u001b[39m(x):\n\u001b[32m  10473\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x._map_values(func, na_action=na_action)\n\u001b[32m> \u001b[39m\u001b[32m10475\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43minfer\u001b[49m\u001b[43m)\u001b[49m.__finalize__(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmap\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\frame.py:10381\u001b[39m, in \u001b[36mDataFrame.apply\u001b[39m\u001b[34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[39m\n\u001b[32m  10367\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapply\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[32m  10369\u001b[39m op = frame_apply(\n\u001b[32m  10370\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m  10371\u001b[39m     func=func,\n\u001b[32m   (...)\u001b[39m\u001b[32m  10379\u001b[39m     kwargs=kwargs,\n\u001b[32m  10380\u001b[39m )\n\u001b[32m> \u001b[39m\u001b[32m10381\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.__finalize__(\u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mapply\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\apply.py:916\u001b[39m, in \u001b[36mFrameApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    913\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raw:\n\u001b[32m    914\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_raw(engine=\u001b[38;5;28mself\u001b[39m.engine, engine_kwargs=\u001b[38;5;28mself\u001b[39m.engine_kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m916\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\apply.py:1063\u001b[39m, in \u001b[36mFrameApply.apply_standard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1061\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m   1062\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.engine == \u001b[33m\"\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1063\u001b[39m         results, res_index = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1064\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1065\u001b[39m         results, res_index = \u001b[38;5;28mself\u001b[39m.apply_series_numba()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\apply.py:1081\u001b[39m, in \u001b[36mFrameApply.apply_series_generator\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1078\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[33m\"\u001b[39m\u001b[33mmode.chained_assignment\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   1079\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[32m   1080\u001b[39m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1081\u001b[39m         results[i] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1082\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[32m   1083\u001b[39m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[32m   1084\u001b[39m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[32m   1085\u001b[39m             results[i] = results[i].copy(deep=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\frame.py:10473\u001b[39m, in \u001b[36mDataFrame.map.<locals>.infer\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m  10472\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minfer\u001b[39m(x):\n\u001b[32m> \u001b[39m\u001b[32m10473\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\base.py:925\u001b[39m, in \u001b[36mIndexOpsMixin._map_values\u001b[39m\u001b[34m(self, mapper, na_action, convert)\u001b[39m\n\u001b[32m    922\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[32m    923\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m arr.map(mapper, na_action=na_action)\n\u001b[32m--> \u001b[39m\u001b[32m925\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[39m, in \u001b[36mmap_array\u001b[39m\u001b[34m(arr, mapper, na_action, convert)\u001b[39m\n\u001b[32m   1741\u001b[39m values = arr.astype(\u001b[38;5;28mobject\u001b[39m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1742\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1743\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1745\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib.map_infer_mask(\n\u001b[32m   1746\u001b[39m         values, mapper, mask=isna(values).view(np.uint8), convert=convert\n\u001b[32m   1747\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/lib.pyx:2999\u001b[39m, in \u001b[36mpandas._libs.lib.map_infer\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[31mTypeError\u001b[39m: preprocess_function() got an unexpected keyword argument 'remove_columns'"
          ]
        }
      ],
      "execution_count": 122
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "def compute_metrics(eval_pred):\n",
        "    # Compute the ROC AUC score\n",
        "    predictions = eval_pred.predictions\n",
        "    predictions = np.exp(predictions)/np.exp(predictions).sum(axis=1, keepdims=True)\n",
        "    label_ids = eval_pred.label_ids\n",
        "    roc_auc = roc_auc_score(label_ids, predictions, average='macro', multi_class='ovr')\n",
        "\n",
        "    # Calculate accuracy using the loaded accuracy metric\n",
        "    acc_score = accuracy.compute(predictions=predictions.argmax(axis=1), references=label_ids)['accuracy']\n",
        "\n",
        "    return {\n",
        "        \"roc_auc\": roc_auc,\n",
        "        \"accuracy\": acc_score\n",
        "    }"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:38:57.96002Z",
          "iopub.execute_input": "2023-11-28T02:38:57.960302Z",
          "iopub.status.idle": "2023-11-28T02:39:00.483542Z",
          "shell.execute_reply.started": "2023-11-28T02:38:57.960278Z",
          "shell.execute_reply": "2023-11-28T02:39:00.482718Z"
        },
        "trusted": true,
        "id": "KQx7qAqfOWNC"
      },
      "outputs": [],
      "execution_count": 112
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and validation"
      ],
      "metadata": {
        "id": "6LD_wLFbOWND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "batch_size=8\n",
        "warmup_steps=50\n",
        "weight_decay=0.02\n",
        "num_train_epochs=10\n",
        "model_name = \"english_accents_classification\"\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=model_name,\n",
        "    logging_dir='./logs',\n",
        "    num_train_epochs=num_train_epochs,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    learning_rate=1e-5, # 3e-5\n",
        "    logging_strategy='steps',\n",
        "    logging_first_step=True,\n",
        "    load_best_model_at_end=True,\n",
        "    logging_steps=1,\n",
        "    evaluation_strategy='epoch',\n",
        "    warmup_steps=warmup_steps,\n",
        "    weight_decay=weight_decay,\n",
        "    eval_steps=1,\n",
        "    gradient_accumulation_steps=1,\n",
        "    gradient_checkpointing=True,\n",
        "    save_strategy='epoch',\n",
        "    save_total_limit=1, # save fewer checkpoints to limit used space\n",
        "    report_to=\"mlflow\",  # log to mlflow\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dd[\"train\"],\n",
        "    eval_dataset=dd[\"test\"],\n",
        "    tokenizer=feature_extractor,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:39:00.484945Z",
          "iopub.execute_input": "2023-11-28T02:39:00.485246Z",
          "iopub.status.idle": "2023-11-28T02:39:02.695947Z",
          "shell.execute_reply.started": "2023-11-28T02:39:00.485218Z",
          "shell.execute_reply": "2023-11-28T02:39:02.694902Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pJRCfnRvOWND",
        "outputId": "176bb86e-c2b2-4460-91bb-3475dedc3356"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'train'",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[31mKeyError\u001b[39m: 'train'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[113]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m      6\u001b[39m model_name = \u001b[33m\"\u001b[39m\u001b[33menglish_accents_classification\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      7\u001b[39m training_args = TrainingArguments(\n\u001b[32m      8\u001b[39m     output_dir=model_name,\n\u001b[32m      9\u001b[39m     logging_dir=\u001b[33m'\u001b[39m\u001b[33m./logs\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     26\u001b[39m     report_to=\u001b[33m\"\u001b[39m\u001b[33mmlflow\u001b[39m\u001b[33m\"\u001b[39m,  \u001b[38;5;66;03m# log to mlflow\u001b[39;00m\n\u001b[32m     27\u001b[39m )\n\u001b[32m     29\u001b[39m trainer = Trainer(\n\u001b[32m     30\u001b[39m     model=model,\n\u001b[32m     31\u001b[39m     args=training_args,\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     train_dataset=\u001b[43mdd\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m,\n\u001b[32m     33\u001b[39m     eval_dataset=dd[\u001b[33m\"\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     34\u001b[39m     tokenizer=feature_extractor,\n\u001b[32m     35\u001b[39m     compute_metrics=compute_metrics,\n\u001b[32m     36\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\frame.py:4107\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4107\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4109\u001b[39m     indexer = [indexer]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
            "\u001b[31mKeyError\u001b[39m: 'train'"
          ]
        }
      ],
      "execution_count": 113
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:39:02.697549Z",
          "iopub.execute_input": "2023-11-28T02:39:02.697857Z",
          "iopub.status.idle": "2023-11-28T02:42:01.649104Z",
          "shell.execute_reply.started": "2023-11-28T02:39:02.697831Z",
          "shell.execute_reply": "2023-11-28T02:42:01.647969Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "v_9vY2P3OWND",
        "outputId": "e6dc1d34-cb94-4457-c471-c538aad0d138"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "You should supply an instance of `transformers.BatchFeature` or list of `transformers.BatchFeature` to this method that includes input_values, but you provided ['label']",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[114]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\trainer.py:2993\u001b[39m, in \u001b[36mTrainer.evaluate\u001b[39m\u001b[34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[39m\n\u001b[32m   2990\u001b[39m start_time = time.time()\n\u001b[32m   2992\u001b[39m eval_loop = \u001b[38;5;28mself\u001b[39m.prediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.use_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.evaluation_loop\n\u001b[32m-> \u001b[39m\u001b[32m2993\u001b[39m output = \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2994\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2995\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mEvaluation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2996\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[32m   2997\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[32m   2998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   2999\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3000\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3001\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3003\u001b[39m total_batch_size = \u001b[38;5;28mself\u001b[39m.args.eval_batch_size * \u001b[38;5;28mself\u001b[39m.args.world_size\n\u001b[32m   3004\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_jit_compilation_time\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output.metrics:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\trainer.py:3164\u001b[39m, in \u001b[36mTrainer.evaluation_loop\u001b[39m\u001b[34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[39m\n\u001b[32m   3162\u001b[39m observed_num_examples = \u001b[32m0\u001b[39m\n\u001b[32m   3163\u001b[39m \u001b[38;5;66;03m# Main evaluation loop\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3164\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3165\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Update the observed num examples\u001b[39;49;00m\n\u001b[32m   3166\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobserved_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mfind_batch_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3167\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:734\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    731\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    732\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    733\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m734\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    735\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    736\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    737\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    739\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    740\u001b[39m ):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:790\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    788\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    789\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m790\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    791\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    792\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:55\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\data\\data_collator.py:249\u001b[39m, in \u001b[36mDataCollatorWithPadding.__call__\u001b[39m\u001b[34m(self, features)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, features: List[Dict[\u001b[38;5;28mstr\u001b[39m, Any]]) -> Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m     batch = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m batch:\n\u001b[32m    257\u001b[39m         batch[\u001b[33m\"\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m\"\u001b[39m] = batch[\u001b[33m\"\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m\"\u001b[39m]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\feature_extraction_sequence_utils.py:132\u001b[39m, in \u001b[36mSequenceFeatureExtractor.pad\u001b[39m\u001b[34m(self, processed_features, padding, max_length, truncation, pad_to_multiple_of, return_attention_mask, return_tensors)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;66;03m# The model's main input name, usually `input_values`, has be passed for padding\u001b[39;00m\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model_input_names[\u001b[32m0\u001b[39m] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m processed_features:\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    133\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou should supply an instance of `transformers.BatchFeature` or list of `transformers.BatchFeature`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    134\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m to this method that includes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.model_input_names[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, but you provided\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    135\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(processed_features.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    136\u001b[39m     )\n\u001b[32m    138\u001b[39m required_input = processed_features[\u001b[38;5;28mself\u001b[39m.model_input_names[\u001b[32m0\u001b[39m]]\n\u001b[32m    139\u001b[39m return_attention_mask = (\n\u001b[32m    140\u001b[39m     return_attention_mask \u001b[38;5;28;01mif\u001b[39;00m return_attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_attention_mask\n\u001b[32m    141\u001b[39m )\n",
            "\u001b[31mValueError\u001b[39m: You should supply an instance of `transformers.BatchFeature` or list of `transformers.BatchFeature` to this method that includes input_values, but you provided ['label']"
          ]
        }
      ],
      "execution_count": 114
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:42:01.650556Z",
          "iopub.execute_input": "2023-11-28T02:42:01.650933Z",
          "iopub.status.idle": "2023-11-28T05:37:47.690098Z",
          "shell.execute_reply.started": "2023-11-28T02:42:01.650897Z",
          "shell.execute_reply": "2023-11-28T05:37:47.689103Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KjIn2dQEOWND",
        "outputId": "d96680ba-a266-4f57-bd4a-db2e2b761f2d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "You should supply an instance of `transformers.BatchFeature` or list of `transformers.BatchFeature` to this method that includes input_values, but you provided ['label']",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[115]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\trainer.py:1662\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   1657\u001b[39m     \u001b[38;5;28mself\u001b[39m.model_wrapped = \u001b[38;5;28mself\u001b[39m.model\n\u001b[32m   1659\u001b[39m inner_training_loop = find_executable_batch_size(\n\u001b[32m   1660\u001b[39m     \u001b[38;5;28mself\u001b[39m._inner_training_loop, \u001b[38;5;28mself\u001b[39m._train_batch_size, args.auto_find_batch_size\n\u001b[32m   1661\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1662\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1663\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1664\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1665\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1666\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1667\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\trainer.py:1899\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   1896\u001b[39m     rng_to_sync = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1898\u001b[39m step = -\u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1899\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1900\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtotal_batched_samples\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m   1901\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrng_to_sync\u001b[49m\u001b[43m:\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:734\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    731\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    732\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    733\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m734\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    735\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    736\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    737\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    739\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    740\u001b[39m ):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:790\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    788\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    789\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m790\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    791\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    792\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:55\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\data\\data_collator.py:249\u001b[39m, in \u001b[36mDataCollatorWithPadding.__call__\u001b[39m\u001b[34m(self, features)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, features: List[Dict[\u001b[38;5;28mstr\u001b[39m, Any]]) -> Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m     batch = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m batch:\n\u001b[32m    257\u001b[39m         batch[\u001b[33m\"\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m\"\u001b[39m] = batch[\u001b[33m\"\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m\"\u001b[39m]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\feature_extraction_sequence_utils.py:132\u001b[39m, in \u001b[36mSequenceFeatureExtractor.pad\u001b[39m\u001b[34m(self, processed_features, padding, max_length, truncation, pad_to_multiple_of, return_attention_mask, return_tensors)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;66;03m# The model's main input name, usually `input_values`, has be passed for padding\u001b[39;00m\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model_input_names[\u001b[32m0\u001b[39m] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m processed_features:\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    133\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou should supply an instance of `transformers.BatchFeature` or list of `transformers.BatchFeature`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    134\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m to this method that includes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.model_input_names[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, but you provided\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    135\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(processed_features.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    136\u001b[39m     )\n\u001b[32m    138\u001b[39m required_input = processed_features[\u001b[38;5;28mself\u001b[39m.model_input_names[\u001b[32m0\u001b[39m]]\n\u001b[32m    139\u001b[39m return_attention_mask = (\n\u001b[32m    140\u001b[39m     return_attention_mask \u001b[38;5;28;01mif\u001b[39;00m return_attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_attention_mask\n\u001b[32m    141\u001b[39m )\n",
            "\u001b[31mValueError\u001b[39m: You should supply an instance of `transformers.BatchFeature` or list of `transformers.BatchFeature` to this method that includes input_values, but you provided ['label']"
          ]
        }
      ],
      "execution_count": 115
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T05:37:47.691181Z",
          "iopub.execute_input": "2023-11-28T05:37:47.691443Z",
          "iopub.status.idle": "2023-11-28T05:40:47.934407Z",
          "shell.execute_reply.started": "2023-11-28T05:37:47.691418Z",
          "shell.execute_reply": "2023-11-28T05:40:47.933474Z"
        },
        "trusted": true,
        "id": "Rg00m675OWND"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T05:40:47.935839Z",
          "iopub.execute_input": "2023-11-28T05:40:47.936163Z",
          "iopub.status.idle": "2023-11-28T05:40:48.521467Z",
          "shell.execute_reply.started": "2023-11-28T05:40:47.936135Z",
          "shell.execute_reply": "2023-11-28T05:40:48.520682Z"
        },
        "trusted": true,
        "id": "crPIzU2MOWND"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "pipe=pipeline('audio-classification',model=model_name,device=0)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T05:40:48.522663Z",
          "iopub.execute_input": "2023-11-28T05:40:48.522953Z",
          "iopub.status.idle": "2023-11-28T05:40:49.754812Z",
          "shell.execute_reply.started": "2023-11-28T05:40:48.522927Z",
          "shell.execute_reply": "2023-11-28T05:40:49.753827Z"
        },
        "trusted": true,
        "id": "EHuqCseCOWNE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# us example\n",
        "audio,rate=torchaudio.load('/kaggle/input/common-voice/cv-valid-test/cv-valid-test/sample-000003.mp3')\n",
        "transform=torchaudio.transforms.Resample(rate,RATE_HZ)\n",
        "audio=transform(audio).numpy().reshape(-1)\n",
        "# make a classification pipeline\n",
        "pipe(audio)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T05:40:49.756039Z",
          "iopub.execute_input": "2023-11-28T05:40:49.75641Z",
          "iopub.status.idle": "2023-11-28T05:40:49.86019Z",
          "shell.execute_reply.started": "2023-11-28T05:40:49.756375Z",
          "shell.execute_reply": "2023-11-28T05:40:49.859265Z"
        },
        "trusted": true,
        "id": "AF0XL4sVOWNE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio\n",
        "Audio(audio,rate=RATE_HZ)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T05:40:49.861478Z",
          "iopub.execute_input": "2023-11-28T05:40:49.863246Z",
          "iopub.status.idle": "2023-11-28T05:40:49.879095Z",
          "shell.execute_reply.started": "2023-11-28T05:40:49.863216Z",
          "shell.execute_reply": "2023-11-28T05:40:49.878252Z"
        },
        "trusted": true,
        "id": "meEiucDMOWNE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# england example\n",
        "audio,rate=torchaudio.load('/kaggle/input/common-voice/cv-valid-test/cv-valid-test/sample-000008.mp3')\n",
        "transform=torchaudio.transforms.Resample(rate,RATE_HZ)\n",
        "audio=transform(audio).numpy().reshape(-1)\n",
        "# make a classification pipeline\n",
        "pipe(audio)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T05:40:49.880557Z",
          "iopub.execute_input": "2023-11-28T05:40:49.880894Z",
          "iopub.status.idle": "2023-11-28T05:40:49.939639Z",
          "shell.execute_reply.started": "2023-11-28T05:40:49.880861Z",
          "shell.execute_reply": "2023-11-28T05:40:49.938817Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "id": "miavQU_JOWNE",
        "outputId": "43708681-8b68-453a-f031-72cb0c382b12"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Couldn't find appropriate backend to handle uri /kaggle/input/common-voice/cv-valid-test/cv-valid-test/sample-000008.mp3 and format None.",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[97]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# england example\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m audio,rate=\u001b[43mtorchaudio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/kaggle/input/common-voice/cv-valid-test/cv-valid-test/sample-000008.mp3\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m transform=torchaudio.transforms.Resample(rate,RATE_HZ)\n\u001b[32m      4\u001b[39m audio=transform(audio).numpy().reshape(-\u001b[32m1\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchaudio\\_backend\\utils.py:221\u001b[39m, in \u001b[36mget_load_func.<locals>.load\u001b[39m\u001b[34m(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size, backend)\u001b[39m\n\u001b[32m    129\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Load audio data from source.\u001b[39;00m\n\u001b[32m    130\u001b[39m \n\u001b[32m    131\u001b[39m \u001b[33;03m.. warning::\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    211\u001b[39m \u001b[33;03m        `[channel, time]` else `[time, channel]`.\u001b[39;00m\n\u001b[32m    212\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    213\u001b[39m warnings.warn(\n\u001b[32m    214\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mIn 2.9, this function\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms implementation will be changed to use \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    215\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtorchaudio.load_with_torchcodec` under the hood. Some \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    219\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mhttps://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    220\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m221\u001b[39m backend = \u001b[43mdispatcher\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    222\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m backend.load(uri, frame_offset, num_frames, normalize, channels_first, \u001b[38;5;28mformat\u001b[39m, buffer_size)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchaudio\\_backend\\utils.py:117\u001b[39m, in \u001b[36mget_load_func.<locals>.dispatcher\u001b[39m\u001b[34m(uri, format, backend_name)\u001b[39m\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m backend.can_decode(uri, \u001b[38;5;28mformat\u001b[39m):\n\u001b[32m    116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m backend\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCouldn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt find appropriate backend to handle uri \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muri\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m and format \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mformat\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[31mRuntimeError\u001b[39m: Couldn't find appropriate backend to handle uri /kaggle/input/common-voice/cv-valid-test/cv-valid-test/sample-000008.mp3 and format None."
          ]
        }
      ],
      "execution_count": 97
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio\n",
        "Audio(audio,rate=RATE_HZ)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T05:40:49.940809Z",
          "iopub.execute_input": "2023-11-28T05:40:49.94117Z",
          "iopub.status.idle": "2023-11-28T05:40:49.954151Z",
          "shell.execute_reply.started": "2023-11-28T05:40:49.941136Z",
          "shell.execute_reply": "2023-11-28T05:40:49.953094Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "2JhXxPA5OWNE",
        "outputId": "6847d5a6-a929-4eb1-ef1f-02f89e3f2637"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'audio' is not defined",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[98]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIPython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Audio\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m Audio(\u001b[43maudio\u001b[49m,rate=RATE_HZ)\n",
            "\u001b[31mNameError\u001b[39m: name 'audio' is not defined"
          ]
        }
      ],
      "execution_count": 98
    },
    {
      "cell_type": "code",
      "source": [
        "# indian example\n",
        "audio,rate=torchaudio.load('/kaggle/input/common-voice/cv-valid-test/cv-valid-test/sample-000033.mp3')\n",
        "transform=torchaudio.transforms.Resample(rate,RATE_HZ)\n",
        "audio=transform(audio).numpy().reshape(-1)\n",
        "# make a classification pipeline\n",
        "pipe(audio)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T05:40:49.955513Z",
          "iopub.execute_input": "2023-11-28T05:40:49.956183Z",
          "iopub.status.idle": "2023-11-28T05:40:50.017313Z",
          "shell.execute_reply.started": "2023-11-28T05:40:49.956146Z",
          "shell.execute_reply": "2023-11-28T05:40:50.01564Z"
        },
        "trusted": true,
        "id": "iVD3WXYfOWNE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio\n",
        "Audio(audio,rate=RATE_HZ)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T05:40:50.019181Z",
          "iopub.execute_input": "2023-11-28T05:40:50.019545Z",
          "iopub.status.idle": "2023-11-28T05:40:50.033665Z",
          "shell.execute_reply.started": "2023-11-28T05:40:50.019507Z",
          "shell.execute_reply": "2023-11-28T05:40:50.032735Z"
        },
        "trusted": true,
        "id": "7mthC4APOWNE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# australia example\n",
        "audio,rate=torchaudio.load('/kaggle/input/common-voice/cv-valid-test/cv-valid-test/sample-000065.mp3')\n",
        "transform=torchaudio.transforms.Resample(rate,RATE_HZ)\n",
        "audio=transform(audio).numpy().reshape(-1)\n",
        "# make a classification pipeline\n",
        "pipe(audio)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T05:40:50.035232Z",
          "iopub.execute_input": "2023-11-28T05:40:50.035944Z",
          "iopub.status.idle": "2023-11-28T05:40:50.082558Z",
          "shell.execute_reply.started": "2023-11-28T05:40:50.035907Z",
          "shell.execute_reply": "2023-11-28T05:40:50.081694Z"
        },
        "trusted": true,
        "id": "JasqsY0LOWNF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio\n",
        "Audio(audio,rate=RATE_HZ)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T05:40:50.083841Z",
          "iopub.execute_input": "2023-11-28T05:40:50.084216Z",
          "iopub.status.idle": "2023-11-28T05:40:50.094218Z",
          "shell.execute_reply.started": "2023-11-28T05:40:50.084185Z",
          "shell.execute_reply": "2023-11-28T05:40:50.093318Z"
        },
        "trusted": true,
        "id": "9wL3lq8bOWNF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# canada example\n",
        "audio,rate=torchaudio.load('/kaggle/input/common-voice/cv-valid-test/cv-valid-test/sample-000037.mp3')\n",
        "transform=torchaudio.transforms.Resample(rate,RATE_HZ)\n",
        "audio=transform(audio).numpy().reshape(-1)\n",
        "# make a classification pipeline\n",
        "pipe(audio)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T05:40:50.09536Z",
          "iopub.execute_input": "2023-11-28T05:40:50.095636Z",
          "iopub.status.idle": "2023-11-28T05:40:50.147389Z",
          "shell.execute_reply.started": "2023-11-28T05:40:50.095611Z",
          "shell.execute_reply": "2023-11-28T05:40:50.146467Z"
        },
        "trusted": true,
        "id": "iNDPR15eOWNF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio\n",
        "Audio(audio,rate=RATE_HZ)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T05:40:50.148655Z",
          "iopub.execute_input": "2023-11-28T05:40:50.14935Z",
          "iopub.status.idle": "2023-11-28T05:40:50.159408Z",
          "shell.execute_reply.started": "2023-11-28T05:40:50.149313Z",
          "shell.execute_reply": "2023-11-28T05:40:50.158598Z"
        },
        "trusted": true,
        "id": "AMPep4P3OWNF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N0N8jWdCOWNF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T-JVQ2uPOWNF"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}