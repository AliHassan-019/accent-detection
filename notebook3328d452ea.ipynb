{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 9812,
          "sourceType": "datasetVersion",
          "datasetId": 5793
        },
        {
          "sourceId": 7063848,
          "sourceType": "datasetVersion",
          "datasetId": 4067020
        }
      ],
      "dockerImageVersionId": 30527,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "notebook3328d452ea",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AliHassan-019/accent-detection/blob/main/notebook3328d452ea.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "mozillaorg_common_voice_path = kagglehub.dataset_download('mozillaorg/common-voice')\n",
        "edolele_speech_commends_path = kagglehub.dataset_download('edolele/speech-commends')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "6WhFaxjvOWMv"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing libraries, loading and transforming data"
      ],
      "metadata": {
        "id": "D_U2rnc3OWMw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q evaluate transformers==4.28.1\n",
        "!pip install -U -q datasets\n",
        "!pip install -q torchaudio==0.12.0+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html\n",
        "!add-apt-repository -y ppa:savoury1/ffmpeg4\n",
        "!apt-get -qq install -y ffmpeg\n",
        "!pip install -q mlflow"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:03:01.989386Z",
          "iopub.execute_input": "2023-11-28T02:03:01.990126Z",
          "iopub.status.idle": "2023-11-28T02:05:54.021447Z",
          "shell.execute_reply.started": "2023-11-28T02:03:01.990093Z",
          "shell.execute_reply": "2023-11-28T02:05:54.020111Z"
        },
        "trusted": true,
        "id": "Ox6rkKK7OWMx"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Torch audio tutorial"
      ],
      "metadata": {
        "id": "A4CqvDtGOWMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchaudio\n",
        "import sys\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython.display as ipd\n",
        "\n",
        "from tqdm import tqdm\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:05:54.024129Z",
          "iopub.execute_input": "2023-11-28T02:05:54.025014Z",
          "iopub.status.idle": "2023-11-28T02:05:55.352452Z",
          "shell.execute_reply.started": "2023-11-28T02:05:54.024967Z",
          "shell.execute_reply": "2023-11-28T02:05:55.350879Z"
        },
        "trusted": true,
        "id": "YgRwQwKHOWMy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from torchaudio.datasets import SPEECHCOMMANDS\n",
        "import os\n",
        "\n",
        "\n",
        "class SubsetSC(SPEECHCOMMANDS):\n",
        "    def __init__(self, subset: str = None):\n",
        "        super().__init__(root = \"/kaggle/input/\", url = '.', download=False, folder_in_archive='speech-commends/')\n",
        "\n",
        "        def load_list(filename):\n",
        "            filepath = os.path.join(self._path, filename)\n",
        "            with open(filepath) as fileobj:\n",
        "\n",
        "                return [os.path.normpath(os.path.join(self._path, line.strip())) for line in fileobj]\n",
        "\n",
        "        if subset == \"validation\":\n",
        "            self._walker = load_list(\"validation_list.txt\")\n",
        "        elif subset == \"testing\":\n",
        "            self._walker = load_list(\"testing_list.txt\")\n",
        "        elif subset == \"training\":\n",
        "            excludes = load_list(\"validation_list.txt\") + load_list(\"testing_list.txt\")\n",
        "            excludes = set(excludes)\n",
        "            self._walker = [w for w in self._walker if w not in excludes]\n",
        "\n",
        "\n",
        "# Create training and testing split of the data. We do not use validation in this tutorial.\n",
        "train_set = SubsetSC(\"training\")\n",
        "test_set = SubsetSC(\"testing\")\n",
        "\n",
        "waveform, sample_rate, label, speaker_id, utterance_number = train_set[0]\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:05:55.355009Z",
          "iopub.execute_input": "2023-11-28T02:05:55.357044Z",
          "iopub.status.idle": "2023-11-28T02:06:05.305646Z",
          "shell.execute_reply.started": "2023-11-28T02:05:55.35698Z",
          "shell.execute_reply": "2023-11-28T02:06:05.304626Z"
        },
        "trusted": true,
        "id": "4XSzYNigOWMy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_set._path"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:06:05.307832Z",
          "iopub.execute_input": "2023-11-28T02:06:05.308176Z",
          "iopub.status.idle": "2023-11-28T02:06:05.315054Z",
          "shell.execute_reply.started": "2023-11-28T02:06:05.308147Z",
          "shell.execute_reply": "2023-11-28T02:06:05.314131Z"
        },
        "trusted": true,
        "id": "lb59joPMOWMy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of waveform: {}\".format(waveform.size()))\n",
        "print(\"Sample rate of waveform: {}\".format(sample_rate))\n",
        "\n",
        "plt.plot(waveform.t().numpy());"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:06:19.675614Z",
          "iopub.execute_input": "2023-11-28T02:06:19.676266Z",
          "iopub.status.idle": "2023-11-28T02:06:19.978712Z",
          "shell.execute_reply.started": "2023-11-28T02:06:19.676232Z",
          "shell.execute_reply": "2023-11-28T02:06:19.973627Z"
        },
        "trusted": true,
        "id": "2WJKXhkKOWMz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ['no',\n",
        " 'two',\n",
        " 'backward',\n",
        " 'four',\n",
        " 'five',\n",
        " 'nine',\n",
        " 'right',\n",
        " 'follow',\n",
        " 'visual',\n",
        " 'off',\n",
        " 'yes',\n",
        " 'six',\n",
        " 'dog',\n",
        " 'learn',\n",
        " 'left',\n",
        " 'bird',\n",
        " 'forward',\n",
        " 'wow',\n",
        " 'zero',\n",
        " 'eight',\n",
        " 'bed',\n",
        " 'go',\n",
        " 'house',\n",
        " 'tree',\n",
        " 'seven',\n",
        " 'on',\n",
        " 'three',\n",
        " 'one',\n",
        " 'down',\n",
        " 'stop',\n",
        " 'up',\n",
        " 'happy',\n",
        " 'marvin',\n",
        " 'cat',\n",
        " 'sheila']"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:06:19.981041Z",
          "iopub.execute_input": "2023-11-28T02:06:19.981619Z",
          "iopub.status.idle": "2023-11-28T02:06:19.989337Z",
          "shell.execute_reply.started": "2023-11-28T02:06:19.98158Z",
          "shell.execute_reply": "2023-11-28T02:06:19.988014Z"
        },
        "trusted": true,
        "id": "zK5FDJ_VOWMz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "waveform_first, *_ = train_set[0]\n",
        "ipd.Audio(waveform_first.numpy(), rate=sample_rate)\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:06:19.990919Z",
          "iopub.execute_input": "2023-11-28T02:06:19.99126Z",
          "iopub.status.idle": "2023-11-28T02:06:20.01696Z",
          "shell.execute_reply.started": "2023-11-28T02:06:19.991226Z",
          "shell.execute_reply": "2023-11-28T02:06:20.015993Z"
        },
        "trusted": true,
        "id": "BIjsQNZeOWMz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "waveform_second, *_ = train_set[-1]\n",
        "ipd.Audio(waveform_second.numpy(), rate=sample_rate)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:06:20.01921Z",
          "iopub.execute_input": "2023-11-28T02:06:20.019504Z",
          "iopub.status.idle": "2023-11-28T02:06:20.034082Z",
          "shell.execute_reply.started": "2023-11-28T02:06:20.019478Z",
          "shell.execute_reply": "2023-11-28T02:06:20.032871Z"
        },
        "trusted": true,
        "id": "qdyF-tEEOWMz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "new_sample_rate = 8000\n",
        "transform = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=new_sample_rate)\n",
        "transformed = transform(waveform_second)\n",
        "\n",
        "ipd.Audio(transformed.numpy(), rate=new_sample_rate)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:06:20.035797Z",
          "iopub.execute_input": "2023-11-28T02:06:20.03615Z",
          "iopub.status.idle": "2023-11-28T02:06:20.047529Z",
          "shell.execute_reply.started": "2023-11-28T02:06:20.036119Z",
          "shell.execute_reply": "2023-11-28T02:06:20.046601Z"
        },
        "trusted": true,
        "id": "2-8ajFKvOWMz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def label_to_index(word):\n",
        "    # Return the position of the word in labels\n",
        "    return torch.tensor(labels.index(word))\n",
        "\n",
        "\n",
        "def index_to_label(index):\n",
        "    # Return the word corresponding to the index in labels\n",
        "    # This is the inverse of label_to_index\n",
        "    return labels[index]\n",
        "\n",
        "\n",
        "word_start = \"yes\"\n",
        "index = label_to_index(word_start)\n",
        "word_recovered = index_to_label(index)\n",
        "\n",
        "print(word_start, \"-->\", index, \"-->\", word_recovered)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:06:20.048771Z",
          "iopub.execute_input": "2023-11-28T02:06:20.049143Z",
          "iopub.status.idle": "2023-11-28T02:06:20.056488Z",
          "shell.execute_reply.started": "2023-11-28T02:06:20.049107Z",
          "shell.execute_reply": "2023-11-28T02:06:20.055603Z"
        },
        "trusted": true,
        "id": "4WcAixD8OWM0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "为了将由录音和话语组成的数据点列表转换为模型的两个批处理张量，我们实现了PyTorch DataLoader使用的collate函数，该函数允许我们分批遍历数据集。有关使用校对函数的更多信息，请参阅文档。\n",
        "\n",
        "\n",
        "\n",
        "在整理函数中，我们还应用了重采样和文本编码。\n",
        "\n"
      ],
      "metadata": {
        "id": "H9bRBffVOWM0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_sequence(batch):\n",
        "    # Make all tensor in a batch the same length by padding with zeros\n",
        "    batch = [item.t() for item in batch]\n",
        "    batch = torch.nn.utils.rnn.pad_sequence(batch, batch_first=True, padding_value=0.)\n",
        "    return batch.permute(0, 2, 1)\n",
        "\n",
        "\n",
        "def collate_fn(batch):\n",
        "\n",
        "    # A data tuple has the form:\n",
        "    # waveform, sample_rate, label, speaker_id, utterance_number\n",
        "\n",
        "    tensors, targets = [], []\n",
        "\n",
        "    # Gather in lists, and encode labels as indices\n",
        "    for waveform, _, label, *_ in batch:\n",
        "        tensors += [waveform]\n",
        "        targets += [label_to_index(label)]\n",
        "\n",
        "    # Group the list of tensors into a batched tensor\n",
        "    tensors = pad_sequence(tensors)\n",
        "    targets = torch.stack(targets)\n",
        "\n",
        "    return tensors, targets\n",
        "\n",
        "\n",
        "batch_size = 256\n",
        "\n",
        "device = 'cuda'\n",
        "\n",
        "if device == \"cuda\":\n",
        "    num_workers = 1\n",
        "    pin_memory = True\n",
        "else:\n",
        "    num_workers = 0\n",
        "    pin_memory = False\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_set,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_fn,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=pin_memory,\n",
        ")\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_set,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    drop_last=False,\n",
        "    collate_fn=collate_fn,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=pin_memory,\n",
        ")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:06:20.057629Z",
          "iopub.execute_input": "2023-11-28T02:06:20.058283Z",
          "iopub.status.idle": "2023-11-28T02:06:20.067709Z",
          "shell.execute_reply.started": "2023-11-28T02:06:20.058247Z",
          "shell.execute_reply": "2023-11-28T02:06:20.066696Z"
        },
        "trusted": true,
        "id": "tFjHZeb9OWM0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "为了将由录音和话语组成的数据点列表转换为模型的两个批处理张量，我们实现了PyTorch DataLoader使用的collate函数，该函数允许我们分批遍历数据集。在本教程中，我们将使用卷积神经网络来处理原始音频数据。通常对音频数据进行更高级的变换，但cnn可以用来准确地处理原始数据。具体的体系结构是在本文描述的M5网络体系结构的基础上建模的。处理原始音频数据的模型的一个重要方面是其第一层滤波器的接受域。我们模型的第一个滤波器的长度是80，所以当处理以8kHz采样的音频时，接收场大约是10ms(而在4kHz时，大约是20ms)。这个大小类似于语音处理应用程序，通常使用20ms到40ms的接受域。"
      ],
      "metadata": {
        "id": "ISxEO96COWM0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class M5(nn.Module):\n",
        "    def __init__(self, n_input=1, n_output=35, stride=16, n_channel=32):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(n_input, n_channel, kernel_size=80, stride=stride)\n",
        "        self.bn1 = nn.BatchNorm1d(n_channel)\n",
        "        self.pool1 = nn.MaxPool1d(4)\n",
        "        self.conv2 = nn.Conv1d(n_channel, n_channel, kernel_size=3)\n",
        "        self.bn2 = nn.BatchNorm1d(n_channel)\n",
        "        self.pool2 = nn.MaxPool1d(4)\n",
        "        self.conv3 = nn.Conv1d(n_channel, 2 * n_channel, kernel_size=3)\n",
        "        self.bn3 = nn.BatchNorm1d(2 * n_channel)\n",
        "        self.pool3 = nn.MaxPool1d(4)\n",
        "        self.conv4 = nn.Conv1d(2 * n_channel, 2 * n_channel, kernel_size=3)\n",
        "        self.bn4 = nn.BatchNorm1d(2 * n_channel)\n",
        "        self.pool4 = nn.MaxPool1d(4)\n",
        "        self.fc1 = nn.Linear(2 * n_channel, n_output)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(self.bn1(x))\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(self.bn2(x))\n",
        "        x = self.pool2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = F.relu(self.bn3(x))\n",
        "        x = self.pool3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = F.relu(self.bn4(x))\n",
        "        x = self.pool4(x)\n",
        "        x = F.avg_pool1d(x, x.shape[-1])\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = self.fc1(x)\n",
        "        return F.log_softmax(x, dim=2)\n",
        "\n",
        "\n",
        "model = M5(n_input=transformed.shape[0], n_output=len(labels))\n",
        "model.to(device)\n",
        "print(model)\n",
        "\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "n = count_parameters(model)\n",
        "print(\"Number of parameters: %s\" % n)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:06:20.06919Z",
          "iopub.execute_input": "2023-11-28T02:06:20.069514Z",
          "iopub.status.idle": "2023-11-28T02:06:21.741515Z",
          "shell.execute_reply.started": "2023-11-28T02:06:20.069482Z",
          "shell.execute_reply": "2023-11-28T02:06:21.740437Z"
        },
        "trusted": true,
        "id": "SJsvQGgQOWM0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=0.0001)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)  # reduce the learning after 20 epochs by a factor of 10"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:06:21.744583Z",
          "iopub.execute_input": "2023-11-28T02:06:21.74488Z",
          "iopub.status.idle": "2023-11-28T02:06:21.750229Z",
          "shell.execute_reply.started": "2023-11-28T02:06:21.744853Z",
          "shell.execute_reply": "2023-11-28T02:06:21.749106Z"
        },
        "trusted": true,
        "id": "LjQx9RTpOWM1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, epoch, log_interval):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "\n",
        "        # apply transform and model on whole batch directly on device\n",
        "        data = transform(data)\n",
        "        output = model(data)\n",
        "\n",
        "        # negative log-likelihood for a tensor of size (batch x 1 x n_output)\n",
        "        loss = F.nll_loss(output.squeeze(), target)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print training stats\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print(f\"Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} ({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}\")\n",
        "\n",
        "        # update progress bar\n",
        "        pbar.update(pbar_update)\n",
        "        # record loss\n",
        "        losses.append(loss.item())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:06:21.75475Z",
          "iopub.execute_input": "2023-11-28T02:06:21.755038Z",
          "iopub.status.idle": "2023-11-28T02:06:21.767742Z",
          "shell.execute_reply.started": "2023-11-28T02:06:21.755013Z",
          "shell.execute_reply": "2023-11-28T02:06:21.766554Z"
        },
        "trusted": true,
        "id": "n4FFAgOkOWM1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def number_of_correct(pred, target):\n",
        "    # count number of correct predictions\n",
        "    return pred.squeeze().eq(target).sum().item()\n",
        "\n",
        "\n",
        "def get_likely_index(tensor):\n",
        "    # find most likely label index for each element in the batch\n",
        "    return tensor.argmax(dim=-1)\n",
        "\n",
        "\n",
        "def test(model, epoch):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    for data, target in test_loader:\n",
        "\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "\n",
        "        # apply transform and model on whole batch directly on device\n",
        "        data = transform(data)\n",
        "        output = model(data)\n",
        "\n",
        "        pred = get_likely_index(output)\n",
        "        correct += number_of_correct(pred, target)\n",
        "\n",
        "        # update progress bar\n",
        "        pbar.update(pbar_update)\n",
        "\n",
        "    print(f\"\\nTest Epoch: {epoch}\\tAccuracy: {correct}/{len(test_loader.dataset)} ({100. * correct / len(test_loader.dataset):.0f}%)\\n\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:06:21.768997Z",
          "iopub.execute_input": "2023-11-28T02:06:21.769354Z",
          "iopub.status.idle": "2023-11-28T02:06:21.783895Z",
          "shell.execute_reply.started": "2023-11-28T02:06:21.76932Z",
          "shell.execute_reply": "2023-11-28T02:06:21.783Z"
        },
        "trusted": true,
        "id": "RcYBf-oxOWM1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "log_interval = 20\n",
        "n_epoch = 2\n",
        "\n",
        "pbar_update = 1 / (len(train_loader) + len(test_loader))\n",
        "losses = []\n",
        "\n",
        "# The transform needs to live on the same device as the model and the data.\n",
        "transform = transform.to(device)\n",
        "with tqdm(total=n_epoch) as pbar:\n",
        "    for epoch in range(1, n_epoch + 1):\n",
        "        train(model, epoch, log_interval)\n",
        "        test(model, epoch)\n",
        "        scheduler.step()\n",
        "\n",
        "# Let's plot the training loss versus the number of iteration.\n",
        "plt.plot(losses);\n",
        "plt.title(\"training loss\");\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:06:21.785205Z",
          "iopub.execute_input": "2023-11-28T02:06:21.785555Z",
          "iopub.status.idle": "2023-11-28T02:21:26.228915Z",
          "shell.execute_reply.started": "2023-11-28T02:06:21.785506Z",
          "shell.execute_reply": "2023-11-28T02:21:26.227875Z"
        },
        "trusted": true,
        "id": "_g206ZcTOWM1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(tensor):\n",
        "    # Use the model to predict the label of the waveform\n",
        "    tensor = tensor.to(device)\n",
        "    tensor = transform(tensor)\n",
        "    tensor = model(tensor.unsqueeze(0))\n",
        "    tensor = get_likely_index(tensor)\n",
        "    tensor = index_to_label(tensor.squeeze())\n",
        "    return tensor\n",
        "\n",
        "\n",
        "waveform, sample_rate, utterance, *_ = train_set[-1]\n",
        "ipd.Audio(waveform.numpy(), rate=sample_rate)\n",
        "\n",
        "print(f\"Expected: {utterance}. Predicted: {predict(waveform)}.\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:21:26.232241Z",
          "iopub.execute_input": "2023-11-28T02:21:26.232538Z",
          "iopub.status.idle": "2023-11-28T02:21:26.253163Z",
          "shell.execute_reply.started": "2023-11-28T02:21:26.232511Z",
          "shell.execute_reply": "2023-11-28T02:21:26.252295Z"
        },
        "trusted": true,
        "id": "330otNoBOWM1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (waveform, sample_rate, utterance, *_) in enumerate(test_set):\n",
        "    output = predict(waveform)\n",
        "    if output != utterance:\n",
        "        ipd.Audio(waveform.numpy(), rate=sample_rate)\n",
        "        print(f\"Data point #{i}. Expected: {utterance}. Predicted: {output}.\")\n",
        "        break\n",
        "else:\n",
        "    print(\"All examples in this dataset were correctly classified!\")\n",
        "    print(\"In this case, let's just look at the last data point\")\n",
        "    ipd.Audio(waveform.numpy(), rate=sample_rate)\n",
        "    print(f\"Data point #{i}. Expected: {utterance}. Predicted: {output}.\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:21:26.25419Z",
          "iopub.execute_input": "2023-11-28T02:21:26.254458Z",
          "iopub.status.idle": "2023-11-28T02:21:26.27228Z",
          "shell.execute_reply.started": "2023-11-28T02:21:26.254433Z",
          "shell.execute_reply": "2023-11-28T02:21:26.271429Z"
        },
        "trusted": true,
        "id": "wDll49OcOWM2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jcjDQoQ8OWM2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rczwpAtOOWM2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZUZXDfsCOWM2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Accent recognition"
      ],
      "metadata": {
        "id": "ZDhWeo-xOWM2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#imports\n",
        "import pandas as pd\n",
        "import gc\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "import torch\n",
        "import torchaudio\n",
        "import datasets\n",
        "import transformers\n",
        "print(transformers.__version__)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:21:26.273369Z",
          "iopub.execute_input": "2023-11-28T02:21:26.273623Z",
          "iopub.status.idle": "2023-11-28T02:21:29.540717Z",
          "shell.execute_reply.started": "2023-11-28T02:21:26.273599Z",
          "shell.execute_reply": "2023-11-28T02:21:29.539705Z"
        },
        "trusted": true,
        "id": "lEYfmAUpOWM2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# use the highest quality data sample for training and validation (leave the test set apart)\n",
        "dd = pd.read_csv(\"/kaggle/input/common-voice/cv-valid-train.csv\").drop_duplicates()\n",
        "dd = dd[~dd['accent'].isnull()]\n",
        "print(dd.shape)\n",
        "dd.sample(5)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:21:29.542206Z",
          "iopub.execute_input": "2023-11-28T02:21:29.543286Z",
          "iopub.status.idle": "2023-11-28T02:21:30.430909Z",
          "shell.execute_reply.started": "2023-11-28T02:21:29.543245Z",
          "shell.execute_reply": "2023-11-28T02:21:30.429963Z"
        },
        "trusted": true,
        "id": "MnNE__plOWM2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dd['accent'].value_counts()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:21:30.432166Z",
          "iopub.execute_input": "2023-11-28T02:21:30.43243Z",
          "iopub.status.idle": "2023-11-28T02:21:30.449785Z",
          "shell.execute_reply.started": "2023-11-28T02:21:30.432406Z",
          "shell.execute_reply": "2023-11-28T02:21:30.448845Z"
        },
        "trusted": true,
        "id": "7LB0QU4XOWM2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "labels = [lang for lang, _ in Counter(dd['accent']).most_common(5)]\n",
        "labels"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:21:30.451243Z",
          "iopub.execute_input": "2023-11-28T02:21:30.451965Z",
          "iopub.status.idle": "2023-11-28T02:21:30.473888Z",
          "shell.execute_reply.started": "2023-11-28T02:21:30.451927Z",
          "shell.execute_reply": "2023-11-28T02:21:30.473006Z"
        },
        "trusted": true,
        "id": "5OIUtvq5OWM2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "RATE_HZ = 16000 # resampling rate in Hz\n",
        "MAX_LENGTH = 40000 # maximum audio interval length to consider (= RATE_HZ * SECONDS)\n",
        "label2id, id2label = dict(), dict()\n",
        "for i, label in enumerate(labels):\n",
        "    label2id[label] = i\n",
        "    id2label[i] = label\n",
        "\n",
        "print(id2label, '\\n\\n', label2id)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:21:30.475004Z",
          "iopub.execute_input": "2023-11-28T02:21:30.475349Z",
          "iopub.status.idle": "2023-11-28T02:21:30.485603Z",
          "shell.execute_reply.started": "2023-11-28T02:21:30.475313Z",
          "shell.execute_reply": "2023-11-28T02:21:30.484823Z"
        },
        "trusted": true,
        "id": "KK5NtACOOWM2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load and preprocess data"
      ],
      "metadata": {
        "id": "RWvSiWZGOWM3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dd = dd[dd['accent'].isin(labels)]\n",
        "dd['label'] = dd['accent'].apply(lambda x: label2id[x])\n",
        "dd = dd[['filename', 'label']]\n",
        "print(dd.shape)\n",
        "dd.sample(5)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:21:30.486697Z",
          "iopub.execute_input": "2023-11-28T02:21:30.487009Z",
          "iopub.status.idle": "2023-11-28T02:21:30.556789Z",
          "shell.execute_reply.started": "2023-11-28T02:21:30.486982Z",
          "shell.execute_reply": "2023-11-28T02:21:30.555847Z"
        },
        "trusted": true,
        "id": "5xU4GENHOWM3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# random undersampling of all but minority class\n",
        "rus = RandomUnderSampler(random_state=83, sampling_strategy='not minority')\n",
        "y = dd[['label']]\n",
        "dd = dd.drop(['label'], axis=1)\n",
        "dd, y_resampled = rus.fit_resample(dd, y)\n",
        "del y\n",
        "dd['label'] = y_resampled\n",
        "del y_resampled\n",
        "gc.collect()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:21:30.557892Z",
          "iopub.execute_input": "2023-11-28T02:21:30.558198Z",
          "iopub.status.idle": "2023-11-28T02:21:30.794835Z",
          "shell.execute_reply.started": "2023-11-28T02:21:30.558172Z",
          "shell.execute_reply": "2023-11-28T02:21:30.793885Z"
        },
        "trusted": true,
        "id": "4dwEz6a4OWM3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dd['label'].value_counts()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:21:30.796258Z",
          "iopub.execute_input": "2023-11-28T02:21:30.796915Z",
          "iopub.status.idle": "2023-11-28T02:21:30.804468Z",
          "shell.execute_reply.started": "2023-11-28T02:21:30.796877Z",
          "shell.execute_reply": "2023-11-28T02:21:30.803443Z"
        },
        "trusted": true,
        "id": "ekiCgoseOWM3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "audio,rate = torchaudio.load(\"/kaggle/input/common-voice/cv-valid-train/\"+dd['filename'].iloc[0])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:21:30.805886Z",
          "iopub.execute_input": "2023-11-28T02:21:30.806262Z",
          "iopub.status.idle": "2023-11-28T02:21:30.865585Z",
          "shell.execute_reply.started": "2023-11-28T02:21:30.806227Z",
          "shell.execute_reply": "2023-11-28T02:21:30.864564Z"
        },
        "trusted": true,
        "id": "wdRVKaeSOWM3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "transform = torchaudio.transforms.Resample(rate,RATE_HZ)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:21:30.866979Z",
          "iopub.execute_input": "2023-11-28T02:21:30.867792Z",
          "iopub.status.idle": "2023-11-28T02:21:30.873036Z",
          "shell.execute_reply.started": "2023-11-28T02:21:30.867752Z",
          "shell.execute_reply": "2023-11-28T02:21:30.872116Z"
        },
        "trusted": true,
        "id": "dDm9fDwoOWM3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "audio = transform(audio).squeeze(0).numpy()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:21:30.874254Z",
          "iopub.execute_input": "2023-11-28T02:21:30.874602Z",
          "iopub.status.idle": "2023-11-28T02:21:30.885618Z",
          "shell.execute_reply.started": "2023-11-28T02:21:30.874567Z",
          "shell.execute_reply": "2023-11-28T02:21:30.884833Z"
        },
        "trusted": true,
        "id": "LgdawQEVOWM3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def get_transform_audio(file):\n",
        "    audio,rate = torchaudio.load(\"/kaggle/input/common-voice/cv-valid-train/\"+str(file))\n",
        "    transform = torchaudio.transforms.Resample(rate,RATE_HZ)\n",
        "    audio = transform(audio).squeeze(0).numpy()\n",
        "    audio = audio[:MAX_LENGTH] # truncate to first part of audio to save RAM\n",
        "    return audio\n",
        "dd['audio'] = dd['filename'].progress_apply(get_transform_audio)\n",
        "gc.collect()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:21:30.886963Z",
          "iopub.execute_input": "2023-11-28T02:21:30.887517Z",
          "iopub.status.idle": "2023-11-28T02:28:32.570348Z",
          "shell.execute_reply.started": "2023-11-28T02:21:30.887481Z",
          "shell.execute_reply": "2023-11-28T02:28:32.569363Z"
        },
        "trusted": true,
        "id": "-rOq_SWzOWNB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "dd = dd.drop(['filename'], axis=1)\n",
        "gc.collect()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:28:32.571768Z",
          "iopub.execute_input": "2023-11-28T02:28:32.572646Z",
          "iopub.status.idle": "2023-11-28T02:28:32.794948Z",
          "shell.execute_reply.started": "2023-11-28T02:28:32.572598Z",
          "shell.execute_reply": "2023-11-28T02:28:32.794042Z"
        },
        "trusted": true,
        "id": "drVchiH8OWNB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dd.sample(5)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:28:32.800794Z",
          "iopub.execute_input": "2023-11-28T02:28:32.801109Z",
          "iopub.status.idle": "2023-11-28T02:28:32.823465Z",
          "shell.execute_reply.started": "2023-11-28T02:28:32.801074Z",
          "shell.execute_reply": "2023-11-28T02:28:32.822415Z"
        },
        "trusted": true,
        "id": "r9B6NobeOWNC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "dd = Dataset.from_pandas(dd)\n",
        "gc.collect()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:28:32.82485Z",
          "iopub.execute_input": "2023-11-28T02:28:32.825197Z",
          "iopub.status.idle": "2023-11-28T02:28:48.157622Z",
          "shell.execute_reply.started": "2023-11-28T02:28:32.825168Z",
          "shell.execute_reply": "2023-11-28T02:28:48.156669Z"
        },
        "trusted": true,
        "id": "FygyoIDKOWNC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "Counter(dd['label']).items()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:28:48.159369Z",
          "iopub.execute_input": "2023-11-28T02:28:48.159662Z",
          "iopub.status.idle": "2023-11-28T02:28:48.182526Z",
          "shell.execute_reply.started": "2023-11-28T02:28:48.159634Z",
          "shell.execute_reply": "2023-11-28T02:28:48.181695Z"
        },
        "trusted": true,
        "id": "gii4u0WlOWNC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dd = dd.train_test_split(test_size=0.25)\n",
        "gc.collect()\n",
        "dd"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:28:48.183916Z",
          "iopub.execute_input": "2023-11-28T02:28:48.184217Z",
          "iopub.status.idle": "2023-11-28T02:28:48.418473Z",
          "shell.execute_reply.started": "2023-11-28T02:28:48.18419Z",
          "shell.execute_reply": "2023-11-28T02:28:48.417534Z"
        },
        "trusted": true,
        "id": "s5aY7l6gOWNC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load facebook/wav2vec2-base-960h model"
      ],
      "metadata": {
        "id": "MIl7WeUlOWNC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoFeatureExtractor, AutoModelForAudioClassification\n",
        "\n",
        "model_str = \"facebook/wav2vec2-base-960h\"\n",
        "feature_extractor=AutoFeatureExtractor.from_pretrained(model_str)\n",
        "model=AutoModelForAudioClassification.from_pretrained(model_str,num_labels=len(labels))\n",
        "model.config.id2label = id2label\n",
        "# number of trainable parameters\n",
        "print(model.num_parameters(only_trainable=True)/1e6)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:28:48.420009Z",
          "iopub.execute_input": "2023-11-28T02:28:48.420335Z",
          "iopub.status.idle": "2023-11-28T02:28:53.134833Z",
          "shell.execute_reply.started": "2023-11-28T02:28:48.420308Z",
          "shell.execute_reply": "2023-11-28T02:28:53.133928Z"
        },
        "trusted": true,
        "id": "ftwTWIQuOWNC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(batch):\n",
        "    inputs = feature_extractor(batch['audio'], sampling_rate=RATE_HZ, max_length=MAX_LENGTH, truncation=True)\n",
        "    inputs['input_values'] = inputs['input_values'][0]\n",
        "    return inputs\n",
        "\n",
        "dd['train'] = dd['train'].map(preprocess_function, remove_columns=\"audio\", batched=False)\n",
        "gc.collect()\n",
        "dd['test'] = dd['test'].map(preprocess_function, remove_columns=\"audio\", batched=False)\n",
        "gc.collect()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:28:53.136323Z",
          "iopub.execute_input": "2023-11-28T02:28:53.136963Z",
          "iopub.status.idle": "2023-11-28T02:38:57.958798Z",
          "shell.execute_reply.started": "2023-11-28T02:28:53.136924Z",
          "shell.execute_reply": "2023-11-28T02:38:57.957802Z"
        },
        "trusted": true,
        "id": "wXy9pq5OOWNC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "def compute_metrics(eval_pred):\n",
        "    # Compute the ROC AUC score\n",
        "    predictions = eval_pred.predictions\n",
        "    predictions = np.exp(predictions)/np.exp(predictions).sum(axis=1, keepdims=True)\n",
        "    label_ids = eval_pred.label_ids\n",
        "    roc_auc = roc_auc_score(label_ids, predictions, average='macro', multi_class='ovr')\n",
        "\n",
        "    # Calculate accuracy using the loaded accuracy metric\n",
        "    acc_score = accuracy.compute(predictions=predictions.argmax(axis=1), references=label_ids)['accuracy']\n",
        "\n",
        "    return {\n",
        "        \"roc_auc\": roc_auc,\n",
        "        \"accuracy\": acc_score\n",
        "    }"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:38:57.96002Z",
          "iopub.execute_input": "2023-11-28T02:38:57.960302Z",
          "iopub.status.idle": "2023-11-28T02:39:00.483542Z",
          "shell.execute_reply.started": "2023-11-28T02:38:57.960278Z",
          "shell.execute_reply": "2023-11-28T02:39:00.482718Z"
        },
        "trusted": true,
        "id": "KQx7qAqfOWNC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and validation"
      ],
      "metadata": {
        "id": "6LD_wLFbOWND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "batch_size=8\n",
        "warmup_steps=50\n",
        "weight_decay=0.02\n",
        "num_train_epochs=10\n",
        "model_name = \"english_accents_classification\"\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=model_name,\n",
        "    logging_dir='./logs',\n",
        "    num_train_epochs=num_train_epochs,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    learning_rate=1e-5, # 3e-5\n",
        "    logging_strategy='steps',\n",
        "    logging_first_step=True,\n",
        "    load_best_model_at_end=True,\n",
        "    logging_steps=1,\n",
        "    evaluation_strategy='epoch',\n",
        "    warmup_steps=warmup_steps,\n",
        "    weight_decay=weight_decay,\n",
        "    eval_steps=1,\n",
        "    gradient_accumulation_steps=1,\n",
        "    gradient_checkpointing=True,\n",
        "    save_strategy='epoch',\n",
        "    save_total_limit=1, # save fewer checkpoints to limit used space\n",
        "    report_to=\"mlflow\",  # log to mlflow\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dd[\"train\"],\n",
        "    eval_dataset=dd[\"test\"],\n",
        "    tokenizer=feature_extractor,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:39:00.484945Z",
          "iopub.execute_input": "2023-11-28T02:39:00.485246Z",
          "iopub.status.idle": "2023-11-28T02:39:02.695947Z",
          "shell.execute_reply.started": "2023-11-28T02:39:00.485218Z",
          "shell.execute_reply": "2023-11-28T02:39:02.694902Z"
        },
        "trusted": true,
        "id": "pJRCfnRvOWND"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:39:02.697549Z",
          "iopub.execute_input": "2023-11-28T02:39:02.697857Z",
          "iopub.status.idle": "2023-11-28T02:42:01.649104Z",
          "shell.execute_reply.started": "2023-11-28T02:39:02.697831Z",
          "shell.execute_reply": "2023-11-28T02:42:01.647969Z"
        },
        "trusted": true,
        "id": "v_9vY2P3OWND"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T02:42:01.650556Z",
          "iopub.execute_input": "2023-11-28T02:42:01.650933Z",
          "iopub.status.idle": "2023-11-28T05:37:47.690098Z",
          "shell.execute_reply.started": "2023-11-28T02:42:01.650897Z",
          "shell.execute_reply": "2023-11-28T05:37:47.689103Z"
        },
        "trusted": true,
        "id": "KjIn2dQEOWND"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T05:37:47.691181Z",
          "iopub.execute_input": "2023-11-28T05:37:47.691443Z",
          "iopub.status.idle": "2023-11-28T05:40:47.934407Z",
          "shell.execute_reply.started": "2023-11-28T05:37:47.691418Z",
          "shell.execute_reply": "2023-11-28T05:40:47.933474Z"
        },
        "trusted": true,
        "id": "Rg00m675OWND"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T05:40:47.935839Z",
          "iopub.execute_input": "2023-11-28T05:40:47.936163Z",
          "iopub.status.idle": "2023-11-28T05:40:48.521467Z",
          "shell.execute_reply.started": "2023-11-28T05:40:47.936135Z",
          "shell.execute_reply": "2023-11-28T05:40:48.520682Z"
        },
        "trusted": true,
        "id": "crPIzU2MOWND"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "pipe=pipeline('audio-classification',model=model_name,device=0)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T05:40:48.522663Z",
          "iopub.execute_input": "2023-11-28T05:40:48.522953Z",
          "iopub.status.idle": "2023-11-28T05:40:49.754812Z",
          "shell.execute_reply.started": "2023-11-28T05:40:48.522927Z",
          "shell.execute_reply": "2023-11-28T05:40:49.753827Z"
        },
        "trusted": true,
        "id": "EHuqCseCOWNE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# us example\n",
        "audio,rate=torchaudio.load('/kaggle/input/common-voice/cv-valid-test/cv-valid-test/sample-000003.mp3')\n",
        "transform=torchaudio.transforms.Resample(rate,RATE_HZ)\n",
        "audio=transform(audio).numpy().reshape(-1)\n",
        "# make a classification pipeline\n",
        "pipe(audio)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T05:40:49.756039Z",
          "iopub.execute_input": "2023-11-28T05:40:49.75641Z",
          "iopub.status.idle": "2023-11-28T05:40:49.86019Z",
          "shell.execute_reply.started": "2023-11-28T05:40:49.756375Z",
          "shell.execute_reply": "2023-11-28T05:40:49.859265Z"
        },
        "trusted": true,
        "id": "AF0XL4sVOWNE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio\n",
        "Audio(audio,rate=RATE_HZ)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T05:40:49.861478Z",
          "iopub.execute_input": "2023-11-28T05:40:49.863246Z",
          "iopub.status.idle": "2023-11-28T05:40:49.879095Z",
          "shell.execute_reply.started": "2023-11-28T05:40:49.863216Z",
          "shell.execute_reply": "2023-11-28T05:40:49.878252Z"
        },
        "trusted": true,
        "id": "meEiucDMOWNE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# england example\n",
        "audio,rate=torchaudio.load('/kaggle/input/common-voice/cv-valid-test/cv-valid-test/sample-000008.mp3')\n",
        "transform=torchaudio.transforms.Resample(rate,RATE_HZ)\n",
        "audio=transform(audio).numpy().reshape(-1)\n",
        "# make a classification pipeline\n",
        "pipe(audio)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T05:40:49.880557Z",
          "iopub.execute_input": "2023-11-28T05:40:49.880894Z",
          "iopub.status.idle": "2023-11-28T05:40:49.939639Z",
          "shell.execute_reply.started": "2023-11-28T05:40:49.880861Z",
          "shell.execute_reply": "2023-11-28T05:40:49.938817Z"
        },
        "trusted": true,
        "id": "miavQU_JOWNE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio\n",
        "Audio(audio,rate=RATE_HZ)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T05:40:49.940809Z",
          "iopub.execute_input": "2023-11-28T05:40:49.94117Z",
          "iopub.status.idle": "2023-11-28T05:40:49.954151Z",
          "shell.execute_reply.started": "2023-11-28T05:40:49.941136Z",
          "shell.execute_reply": "2023-11-28T05:40:49.953094Z"
        },
        "trusted": true,
        "id": "2JhXxPA5OWNE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# indian example\n",
        "audio,rate=torchaudio.load('/kaggle/input/common-voice/cv-valid-test/cv-valid-test/sample-000033.mp3')\n",
        "transform=torchaudio.transforms.Resample(rate,RATE_HZ)\n",
        "audio=transform(audio).numpy().reshape(-1)\n",
        "# make a classification pipeline\n",
        "pipe(audio)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T05:40:49.955513Z",
          "iopub.execute_input": "2023-11-28T05:40:49.956183Z",
          "iopub.status.idle": "2023-11-28T05:40:50.017313Z",
          "shell.execute_reply.started": "2023-11-28T05:40:49.956146Z",
          "shell.execute_reply": "2023-11-28T05:40:50.01564Z"
        },
        "trusted": true,
        "id": "iVD3WXYfOWNE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio\n",
        "Audio(audio,rate=RATE_HZ)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T05:40:50.019181Z",
          "iopub.execute_input": "2023-11-28T05:40:50.019545Z",
          "iopub.status.idle": "2023-11-28T05:40:50.033665Z",
          "shell.execute_reply.started": "2023-11-28T05:40:50.019507Z",
          "shell.execute_reply": "2023-11-28T05:40:50.032735Z"
        },
        "trusted": true,
        "id": "7mthC4APOWNE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# australia example\n",
        "audio,rate=torchaudio.load('/kaggle/input/common-voice/cv-valid-test/cv-valid-test/sample-000065.mp3')\n",
        "transform=torchaudio.transforms.Resample(rate,RATE_HZ)\n",
        "audio=transform(audio).numpy().reshape(-1)\n",
        "# make a classification pipeline\n",
        "pipe(audio)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T05:40:50.035232Z",
          "iopub.execute_input": "2023-11-28T05:40:50.035944Z",
          "iopub.status.idle": "2023-11-28T05:40:50.082558Z",
          "shell.execute_reply.started": "2023-11-28T05:40:50.035907Z",
          "shell.execute_reply": "2023-11-28T05:40:50.081694Z"
        },
        "trusted": true,
        "id": "JasqsY0LOWNF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio\n",
        "Audio(audio,rate=RATE_HZ)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T05:40:50.083841Z",
          "iopub.execute_input": "2023-11-28T05:40:50.084216Z",
          "iopub.status.idle": "2023-11-28T05:40:50.094218Z",
          "shell.execute_reply.started": "2023-11-28T05:40:50.084185Z",
          "shell.execute_reply": "2023-11-28T05:40:50.093318Z"
        },
        "trusted": true,
        "id": "9wL3lq8bOWNF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# canada example\n",
        "audio,rate=torchaudio.load('/kaggle/input/common-voice/cv-valid-test/cv-valid-test/sample-000037.mp3')\n",
        "transform=torchaudio.transforms.Resample(rate,RATE_HZ)\n",
        "audio=transform(audio).numpy().reshape(-1)\n",
        "# make a classification pipeline\n",
        "pipe(audio)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T05:40:50.09536Z",
          "iopub.execute_input": "2023-11-28T05:40:50.095636Z",
          "iopub.status.idle": "2023-11-28T05:40:50.147389Z",
          "shell.execute_reply.started": "2023-11-28T05:40:50.095611Z",
          "shell.execute_reply": "2023-11-28T05:40:50.146467Z"
        },
        "trusted": true,
        "id": "iNDPR15eOWNF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio\n",
        "Audio(audio,rate=RATE_HZ)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-28T05:40:50.148655Z",
          "iopub.execute_input": "2023-11-28T05:40:50.14935Z",
          "iopub.status.idle": "2023-11-28T05:40:50.159408Z",
          "shell.execute_reply.started": "2023-11-28T05:40:50.149313Z",
          "shell.execute_reply": "2023-11-28T05:40:50.158598Z"
        },
        "trusted": true,
        "id": "AMPep4P3OWNF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N0N8jWdCOWNF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T-JVQ2uPOWNF"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}